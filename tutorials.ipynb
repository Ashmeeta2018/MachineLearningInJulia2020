{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learning in Julia, JuliaCon2020"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A workshop introducing the machine learning toolbox\n",
    "[MLJ](https://alan-turing-institute.github.io/MLJ.jl/stable/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Environment instantiation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This line loads a Julia environment (defined in Project.toml and Manifest.toml files which must be in the same directory as this file):"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Activating environment at `~/Dropbox/Julia7/MLJ/MachineLearningInJulia2020/Project.toml`\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "include(joinpath(@__DIR__, \"setup.jl\"))"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 1: Data Representation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Goals:**\n",
    "> 1. Learn how MLJ specifies it's data requirements using \"scientific\" types\n",
    "> 2. Understand the options for representing tabular data\n",
    "> 3. Learn how to inspect and fix the representation of data to meet MLJ requirements"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Scientific types"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To help you focus on the intended *purpose* or *interpretation* of\n",
    "data, MLJ models specify data requirements using *scientific types*,\n",
    "instead of machine types. An example of a scientific type is\n",
    "`OrderedFactor`. The other basic \"scalar\" scientific types are\n",
    "illustrated below:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](assets/scitypes.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A scientific type is an ordinary Julia type (so it can be used for\n",
    "method dispatch, for example) but it usually has no instances. The\n",
    "`scitype` function is used to articulate MLJ's convention about how\n",
    "different machine types will be interpreted by MLJ models:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Continuous"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "cell_type": "code",
   "source": [
    "using MLJ\n",
    "scitype(3.141)"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "AbstractArray{Continuous,1}"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "cell_type": "code",
   "source": [
    "time = [2.3, 4.5, 4.2, 1.8, 7.1]\n",
    "scitype(time)"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "To fix data which MLJ is interpreting incorrectly, we use the\n",
    "`coerce` method:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "AbstractArray{Count,1}"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "height = [185, 153, 163, 114, 180]\n",
    "scitype(height)"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "5-element Array{Float64,1}:\n 185.0\n 153.0\n 163.0\n 114.0\n 180.0"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "cell_type": "code",
   "source": [
    "height = coerce(height, Continuous)"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here's an example of data we would want interpreted as\n",
    "`OrderedFactor` but isn't:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "AbstractArray{Union{Missing, Textual},1}"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "cell_type": "code",
   "source": [
    "exam_mark = [\"rotten\", \"great\", \"bla\",  missing, \"great\"]\n",
    "scitype(exam_mark)"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Info: Trying to coerce from `Union{Missing, String}` to `OrderedFactor`.\n",
      "│ Coerced to `Union{Missing,OrderedFactor}` instead.\n",
      "└ @ MLJScientificTypes /Users/anthony/.julia/packages/MLJScientificTypes/wqfgN/src/convention/coerce.jl:126\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "5-element CategoricalArray{Union{Missing, String},1,UInt32}:\n \"rotten\"\n \"great\"\n \"bla\"\n missing\n \"great\""
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "cell_type": "code",
   "source": [
    "exam_mark = coerce(exam_mark, OrderedFactor)"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3-element Array{String,1}:\n \"bla\"\n \"great\"\n \"rotten\""
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "cell_type": "code",
   "source": [
    "levels(exam_mark)"
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use `levels!` to put the classes in the right order:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "true"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "cell_type": "code",
   "source": [
    "levels!(exam_mark, [\"rotten\", \"bla\", \"great\"])\n",
    "exam_mark[1] < exam_mark[2]"
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "When subsampling, no levels are not lost:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3-element Array{String,1}:\n \"rotten\"\n \"bla\"\n \"great\""
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "cell_type": "code",
   "source": [
    "levels(exam_mark[1:2])"
   ],
   "metadata": {},
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Note on binary data.** There is no separate scientific type for binary\n",
    "data. Binary data is `OrderedFactor{2}` if it has an intrinsic\n",
    "\"true\" class (eg, \"pass\"/\"fail\") and `Multiclass{2}` otherwise (eg,\n",
    "\"male\"/\"female\")."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Two-dimensional data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Whenever it makes sense, MLJ Models generally expect two-dimensional\n",
    "data to be *tabular*. All the tabular formats implementing the\n",
    "[Tables.jl API](https://juliadata.github.io/Tables.jl/stable/) (see\n",
    "this\n",
    "[list](https://github.com/JuliaData/Tables.jl/blob/master/INTEGRATIONS.md))\n",
    "have a scientific type of `Table` and can be used with such models."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The simplest example of a table is a the julia native *column\n",
    "table*, which is just a named tuple of equal-length vectors:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(h = [185.0, 153.0, 163.0, 114.0, 180.0],\n e = Union{Missing, CategoricalValue{String,UInt32}}[\"rotten\", \"great\", \"bla\", missing, \"great\"],\n t = [2.3, 4.5, 4.2, 1.8, 7.1],)"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "cell_type": "code",
   "source": [
    "column_table = (h=height, e=exam_mark, t=time)"
   ],
   "metadata": {},
   "execution_count": 11
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Table{Union{AbstractArray{Union{Missing, OrderedFactor{3}},1}, AbstractArray{Continuous,1}}}"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "cell_type": "code",
   "source": [
    "scitype(column_table)"
   ],
   "metadata": {},
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice the `Table{K}` type parameter `K` encodes the scientific\n",
    "types of the columns. (This is useful when comparing table scitypes\n",
    "with `<:`). To inspect the individual column scitypes, we use the\n",
    "`schema` method instead:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "┌\u001b[0m─────────\u001b[0m┬\u001b[0m─────────────────────────────────────────────────\u001b[0m┬\u001b[0m──────────────────────────────────\u001b[0m┐\u001b[0m\n│\u001b[0m\u001b[22m _.names \u001b[0m│\u001b[0m\u001b[22m _.types                                         \u001b[0m│\u001b[0m\u001b[22m _.scitypes                       \u001b[0m│\u001b[0m\n├\u001b[0m─────────\u001b[0m┼\u001b[0m─────────────────────────────────────────────────\u001b[0m┼\u001b[0m──────────────────────────────────\u001b[0m┤\u001b[0m\n│\u001b[0m h       \u001b[0m│\u001b[0m Float64                                         \u001b[0m│\u001b[0m Continuous                       \u001b[0m│\u001b[0m\n│\u001b[0m e       \u001b[0m│\u001b[0m Union{Missing, CategoricalValue{String,UInt32}} \u001b[0m│\u001b[0m Union{Missing, OrderedFactor{3}} \u001b[0m│\u001b[0m\n│\u001b[0m t       \u001b[0m│\u001b[0m Float64                                         \u001b[0m│\u001b[0m Continuous                       \u001b[0m│\u001b[0m\n└\u001b[0m─────────\u001b[0m┴\u001b[0m─────────────────────────────────────────────────\u001b[0m┴\u001b[0m──────────────────────────────────\u001b[0m┘\u001b[0m\n_.nrows = 5\n"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "cell_type": "code",
   "source": [
    "schema(column_table)"
   ],
   "metadata": {},
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here are four other examples of tables:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "┌\u001b[0m─────────\u001b[0m┬\u001b[0m─────────\u001b[0m┬\u001b[0m────────────\u001b[0m┐\u001b[0m\n│\u001b[0m\u001b[22m _.names \u001b[0m│\u001b[0m\u001b[22m _.types \u001b[0m│\u001b[0m\u001b[22m _.scitypes \u001b[0m│\u001b[0m\n├\u001b[0m─────────\u001b[0m┼\u001b[0m─────────\u001b[0m┼\u001b[0m────────────\u001b[0m┤\u001b[0m\n│\u001b[0m a       \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n│\u001b[0m b       \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n└\u001b[0m─────────\u001b[0m┴\u001b[0m─────────\u001b[0m┴\u001b[0m────────────\u001b[0m┘\u001b[0m\n_.nrows = 3\n"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "cell_type": "code",
   "source": [
    "row_table = [(a=1, b=3.4),\n",
    "             (a=2, b=4.5),\n",
    "             (a=3, b=5.6)]\n",
    "schema(row_table)"
   ],
   "metadata": {},
   "execution_count": 14
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "5×3 DataFrame\n│ Row │ h       │ e       │ t       │\n│     │ \u001b[90mFloat64\u001b[39m │ \u001b[90mCat…?\u001b[39m   │ \u001b[90mFloat64\u001b[39m │\n├─────┼─────────┼─────────┼─────────┤\n│ 1   │ 185.0   │ rotten  │ 2.3     │\n│ 2   │ 153.0   │ great   │ 4.5     │\n│ 3   │ 163.0   │ bla     │ 4.2     │\n│ 4   │ 114.0   │ \u001b[90mmissing\u001b[39m │ 1.8     │\n│ 5   │ 180.0   │ great   │ 7.1     │",
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>h</th><th>e</th><th>t</th></tr><tr><th></th><th>Float64</th><th>Cat…?</th><th>Float64</th></tr></thead><tbody><p>5 rows × 3 columns</p><tr><th>1</th><td>185.0</td><td>rotten</td><td>2.3</td></tr><tr><th>2</th><td>153.0</td><td>great</td><td>4.5</td></tr><tr><th>3</th><td>163.0</td><td>bla</td><td>4.2</td></tr><tr><th>4</th><td>114.0</td><td><em>missing</em></td><td>1.8</td></tr><tr><th>5</th><td>180.0</td><td>great</td><td>7.1</td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "cell_type": "code",
   "source": [
    "import DataFrames\n",
    "df = DataFrames.DataFrame(column_table)"
   ],
   "metadata": {},
   "execution_count": 15
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "┌\u001b[0m─────────\u001b[0m┬\u001b[0m─────────────────────────────────────────────────\u001b[0m┬\u001b[0m──────────────────────────────────\u001b[0m┐\u001b[0m\n│\u001b[0m\u001b[22m _.names \u001b[0m│\u001b[0m\u001b[22m _.types                                         \u001b[0m│\u001b[0m\u001b[22m _.scitypes                       \u001b[0m│\u001b[0m\n├\u001b[0m─────────\u001b[0m┼\u001b[0m─────────────────────────────────────────────────\u001b[0m┼\u001b[0m──────────────────────────────────\u001b[0m┤\u001b[0m\n│\u001b[0m h       \u001b[0m│\u001b[0m Float64                                         \u001b[0m│\u001b[0m Continuous                       \u001b[0m│\u001b[0m\n│\u001b[0m e       \u001b[0m│\u001b[0m Union{Missing, CategoricalValue{String,UInt32}} \u001b[0m│\u001b[0m Union{Missing, OrderedFactor{3}} \u001b[0m│\u001b[0m\n│\u001b[0m t       \u001b[0m│\u001b[0m Float64                                         \u001b[0m│\u001b[0m Continuous                       \u001b[0m│\u001b[0m\n└\u001b[0m─────────\u001b[0m┴\u001b[0m─────────────────────────────────────────────────\u001b[0m┴\u001b[0m──────────────────────────────────\u001b[0m┘\u001b[0m\n_.nrows = 5\n"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "cell_type": "code",
   "source": [
    "schema(df)"
   ],
   "metadata": {},
   "execution_count": 16
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "┌\u001b[0m─────────────────────────\u001b[0m┬\u001b[0m─────────\u001b[0m┬\u001b[0m────────────\u001b[0m┐\u001b[0m\n│\u001b[0m\u001b[22m _.names                 \u001b[0m│\u001b[0m\u001b[22m _.types \u001b[0m│\u001b[0m\u001b[22m _.scitypes \u001b[0m│\u001b[0m\n├\u001b[0m─────────────────────────\u001b[0m┼\u001b[0m─────────\u001b[0m┼\u001b[0m────────────\u001b[0m┤\u001b[0m\n│\u001b[0m surgery                 \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n│\u001b[0m age                     \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n│\u001b[0m rectal_temperature      \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m pulse                   \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n│\u001b[0m respiratory_rate        \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n│\u001b[0m temperature_extremities \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n│\u001b[0m mucous_membranes        \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n│\u001b[0m capillary_refill_time   \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n│\u001b[0m pain                    \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n│\u001b[0m peristalsis             \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n│\u001b[0m abdominal_distension    \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n│\u001b[0m packed_cell_volume      \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m total_protein           \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m outcome                 \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n│\u001b[0m surgical_lesion         \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n│\u001b[0m cp_data                 \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n└\u001b[0m─────────────────────────\u001b[0m┴\u001b[0m─────────\u001b[0m┴\u001b[0m────────────\u001b[0m┘\u001b[0m\n_.nrows = 366\n"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "cell_type": "code",
   "source": [
    "using CSV\n",
    "file = CSV.File(joinpath(DIR, \"data\", \"horse.csv\"));\n",
    "schema(file) # (triggers a file read)"
   ],
   "metadata": {},
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "Most MLJ models do not accept matrix in lieu of a table, but you can\n",
    "wrap a matrix as a table:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "┌\u001b[0m─────────\u001b[0m┬\u001b[0m─────────\u001b[0m┬\u001b[0m────────────\u001b[0m┐\u001b[0m\n│\u001b[0m\u001b[22m _.names \u001b[0m│\u001b[0m\u001b[22m _.types \u001b[0m│\u001b[0m\u001b[22m _.scitypes \u001b[0m│\u001b[0m\n├\u001b[0m─────────\u001b[0m┼\u001b[0m─────────\u001b[0m┼\u001b[0m────────────\u001b[0m┤\u001b[0m\n│\u001b[0m x1      \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m x2      \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m x3      \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n└\u001b[0m─────────\u001b[0m┴\u001b[0m─────────\u001b[0m┴\u001b[0m────────────\u001b[0m┘\u001b[0m\n_.nrows = 2\n"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "cell_type": "code",
   "source": [
    "matrix_table = MLJ.table(rand(2,3))\n",
    "schema(matrix_table)"
   ],
   "metadata": {},
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "Under the hood many algorithms convert tabular data to matrices. If\n",
    "your table is a wrapped matrix like the above, then the compiler\n",
    "will generally collapse the conversions to a no-op."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Manipulating tabular data.** In this workshop we assume\n",
    "familiarity with some kind of tabular data container (although it is\n",
    "possible, in principle, to carry out the exercises without this.)\n",
    "For a quick start introduction to `DataFrames`, see [this\n",
    "tutorial](https://alan-turing-institute.github.io/DataScienceTutorials.jl/data/dataframe/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fixing scientific types in tabular data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To show how we can correct the scientific types of data in tables,\n",
    "we introduce a cleaned up version of the UCI Horse Colic Data Set\n",
    "(the cleaning workflow is described\n",
    "[here](https://alan-turing-institute.github.io/DataScienceTutorials.jl/end-to-end/horse/#dealing_with_missing_values))"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4×16 DataFrame. Omitted printing of 11 columns\n│ Row │ surgery │ age   │ rectal_temperature │ pulse │ respiratory_rate │\n│     │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m │ \u001b[90mFloat64\u001b[39m            │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m            │\n├─────┼─────────┼───────┼────────────────────┼───────┼──────────────────┤\n│ 1   │ 2       │ 1     │ 38.5               │ 66    │ 66               │\n│ 2   │ 1       │ 1     │ 39.2               │ 88    │ 88               │\n│ 3   │ 2       │ 1     │ 38.3               │ 40    │ 40               │\n│ 4   │ 1       │ 9     │ 39.1               │ 164   │ 164              │",
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>surgery</th><th>age</th><th>rectal_temperature</th><th>pulse</th><th>respiratory_rate</th><th>temperature_extremities</th><th>mucous_membranes</th></tr><tr><th></th><th>Int64</th><th>Int64</th><th>Float64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>4 rows × 16 columns (omitted printing of 9 columns)</p><tr><th>1</th><td>2</td><td>1</td><td>38.5</td><td>66</td><td>66</td><td>3</td><td>1</td></tr><tr><th>2</th><td>1</td><td>1</td><td>39.2</td><td>88</td><td>88</td><td>3</td><td>4</td></tr><tr><th>3</th><td>2</td><td>1</td><td>38.3</td><td>40</td><td>40</td><td>1</td><td>3</td></tr><tr><th>4</th><td>1</td><td>9</td><td>39.1</td><td>164</td><td>164</td><td>4</td><td>6</td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "cell_type": "code",
   "source": [
    "using CSV\n",
    "file = CSV.File(joinpath(DIR, \"data\", \"horse.csv\"));\n",
    "horse = DataFrames.DataFrame(file); # convert to data frame without copying columns\n",
    "first(horse, 4)"
   ],
   "metadata": {},
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "From [the UCI\n",
    "docs](http://archive.ics.uci.edu/ml/datasets/Horse+Colic) we can\n",
    "surmise how each variable ought to be interpreted (a step in our\n",
    "workflow that cannot reliably be left to the computer):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "variable                    | scientific type (interpretation)\n",
    "----------------------------|-----------------------------------\n",
    "`:surgery`                  | Multiclass\n",
    "`:age`                      | Multiclass\n",
    "`:rectal_temperature`       | Continuous\n",
    "`:pulse`                    | Continuous\n",
    "`:respiratory_rate`         | Continuous\n",
    "`:temperature_extremities`  | OrderedFactor\n",
    "`:mucous_membranes`         | Multiclass\n",
    "`:capillary_refill_time`    | Multiclass\n",
    "`:pain`                     | OrderedFactor\n",
    "`:peristalsis`              | OrderedFactor\n",
    "`:abdominal_distension`     | OrderedFactor\n",
    "`:packed_cell_volume`       | Continuous\n",
    "`:total_protein`            | Continuous\n",
    "`:outcome`                  | Multiclass\n",
    "`:surgical_lesion`          | OrderedFactor\n",
    "`:cp_data`                  | Multiclass"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see how MLJ will actually interpret the data, as it is\n",
    "currently encoded:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "┌\u001b[0m─────────────────────────\u001b[0m┬\u001b[0m─────────\u001b[0m┬\u001b[0m────────────\u001b[0m┐\u001b[0m\n│\u001b[0m\u001b[22m _.names                 \u001b[0m│\u001b[0m\u001b[22m _.types \u001b[0m│\u001b[0m\u001b[22m _.scitypes \u001b[0m│\u001b[0m\n├\u001b[0m─────────────────────────\u001b[0m┼\u001b[0m─────────\u001b[0m┼\u001b[0m────────────\u001b[0m┤\u001b[0m\n│\u001b[0m surgery                 \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n│\u001b[0m age                     \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n│\u001b[0m rectal_temperature      \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m pulse                   \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n│\u001b[0m respiratory_rate        \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n│\u001b[0m temperature_extremities \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n│\u001b[0m mucous_membranes        \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n│\u001b[0m capillary_refill_time   \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n│\u001b[0m pain                    \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n│\u001b[0m peristalsis             \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n│\u001b[0m abdominal_distension    \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n│\u001b[0m packed_cell_volume      \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m total_protein           \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m outcome                 \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n│\u001b[0m surgical_lesion         \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n│\u001b[0m cp_data                 \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n└\u001b[0m─────────────────────────\u001b[0m┴\u001b[0m─────────\u001b[0m┴\u001b[0m────────────\u001b[0m┘\u001b[0m\n_.nrows = 366\n"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "cell_type": "code",
   "source": [
    "schema(horse)"
   ],
   "metadata": {},
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "As a first correction step, we can get MLJ to \"guess\" the\n",
    "appropriate fix, using the `autotype` method:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Dict{Symbol,Type} with 11 entries:\n  :abdominal_distension    => OrderedFactor\n  :pain                    => OrderedFactor\n  :surgery                 => OrderedFactor\n  :mucous_membranes        => OrderedFactor\n  :surgical_lesion         => OrderedFactor\n  :outcome                 => OrderedFactor\n  :capillary_refill_time   => OrderedFactor\n  :age                     => OrderedFactor\n  :temperature_extremities => OrderedFactor\n  :peristalsis             => OrderedFactor\n  :cp_data                 => OrderedFactor"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "cell_type": "code",
   "source": [
    "autotype(horse)"
   ],
   "metadata": {},
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "Okay, this is not perfect, but a step in the right direction, which\n",
    "we implement like this:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "┌\u001b[0m─────────────────────────\u001b[0m┬\u001b[0m────────────────────────────────\u001b[0m┬\u001b[0m──────────────────\u001b[0m┐\u001b[0m\n│\u001b[0m\u001b[22m _.names                 \u001b[0m│\u001b[0m\u001b[22m _.types                        \u001b[0m│\u001b[0m\u001b[22m _.scitypes       \u001b[0m│\u001b[0m\n├\u001b[0m─────────────────────────\u001b[0m┼\u001b[0m────────────────────────────────\u001b[0m┼\u001b[0m──────────────────\u001b[0m┤\u001b[0m\n│\u001b[0m surgery                 \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{2} \u001b[0m│\u001b[0m\n│\u001b[0m age                     \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{2} \u001b[0m│\u001b[0m\n│\u001b[0m rectal_temperature      \u001b[0m│\u001b[0m Float64                        \u001b[0m│\u001b[0m Continuous       \u001b[0m│\u001b[0m\n│\u001b[0m pulse                   \u001b[0m│\u001b[0m Int64                          \u001b[0m│\u001b[0m Count            \u001b[0m│\u001b[0m\n│\u001b[0m respiratory_rate        \u001b[0m│\u001b[0m Int64                          \u001b[0m│\u001b[0m Count            \u001b[0m│\u001b[0m\n│\u001b[0m temperature_extremities \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{4} \u001b[0m│\u001b[0m\n│\u001b[0m mucous_membranes        \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{6} \u001b[0m│\u001b[0m\n│\u001b[0m capillary_refill_time   \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{3} \u001b[0m│\u001b[0m\n│\u001b[0m pain                    \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{5} \u001b[0m│\u001b[0m\n│\u001b[0m peristalsis             \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{4} \u001b[0m│\u001b[0m\n│\u001b[0m abdominal_distension    \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{4} \u001b[0m│\u001b[0m\n│\u001b[0m packed_cell_volume      \u001b[0m│\u001b[0m Float64                        \u001b[0m│\u001b[0m Continuous       \u001b[0m│\u001b[0m\n│\u001b[0m total_protein           \u001b[0m│\u001b[0m Float64                        \u001b[0m│\u001b[0m Continuous       \u001b[0m│\u001b[0m\n│\u001b[0m outcome                 \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{3} \u001b[0m│\u001b[0m\n│\u001b[0m surgical_lesion         \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{2} \u001b[0m│\u001b[0m\n│\u001b[0m cp_data                 \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{2} \u001b[0m│\u001b[0m\n└\u001b[0m─────────────────────────\u001b[0m┴\u001b[0m────────────────────────────────\u001b[0m┴\u001b[0m──────────────────\u001b[0m┘\u001b[0m\n_.nrows = 366\n"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "cell_type": "code",
   "source": [
    "coerce!(horse, autotype(horse));\n",
    "schema(horse)"
   ],
   "metadata": {},
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "All remaining `Count` data should be `Continuous`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "┌\u001b[0m─────────────────────────\u001b[0m┬\u001b[0m────────────────────────────────\u001b[0m┬\u001b[0m──────────────────\u001b[0m┐\u001b[0m\n│\u001b[0m\u001b[22m _.names                 \u001b[0m│\u001b[0m\u001b[22m _.types                        \u001b[0m│\u001b[0m\u001b[22m _.scitypes       \u001b[0m│\u001b[0m\n├\u001b[0m─────────────────────────\u001b[0m┼\u001b[0m────────────────────────────────\u001b[0m┼\u001b[0m──────────────────\u001b[0m┤\u001b[0m\n│\u001b[0m surgery                 \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{2} \u001b[0m│\u001b[0m\n│\u001b[0m age                     \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{2} \u001b[0m│\u001b[0m\n│\u001b[0m rectal_temperature      \u001b[0m│\u001b[0m Float64                        \u001b[0m│\u001b[0m Continuous       \u001b[0m│\u001b[0m\n│\u001b[0m pulse                   \u001b[0m│\u001b[0m Float64                        \u001b[0m│\u001b[0m Continuous       \u001b[0m│\u001b[0m\n│\u001b[0m respiratory_rate        \u001b[0m│\u001b[0m Float64                        \u001b[0m│\u001b[0m Continuous       \u001b[0m│\u001b[0m\n│\u001b[0m temperature_extremities \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{4} \u001b[0m│\u001b[0m\n│\u001b[0m mucous_membranes        \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{6} \u001b[0m│\u001b[0m\n│\u001b[0m capillary_refill_time   \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{3} \u001b[0m│\u001b[0m\n│\u001b[0m pain                    \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{5} \u001b[0m│\u001b[0m\n│\u001b[0m peristalsis             \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{4} \u001b[0m│\u001b[0m\n│\u001b[0m abdominal_distension    \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{4} \u001b[0m│\u001b[0m\n│\u001b[0m packed_cell_volume      \u001b[0m│\u001b[0m Float64                        \u001b[0m│\u001b[0m Continuous       \u001b[0m│\u001b[0m\n│\u001b[0m total_protein           \u001b[0m│\u001b[0m Float64                        \u001b[0m│\u001b[0m Continuous       \u001b[0m│\u001b[0m\n│\u001b[0m outcome                 \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{3} \u001b[0m│\u001b[0m\n│\u001b[0m surgical_lesion         \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{2} \u001b[0m│\u001b[0m\n│\u001b[0m cp_data                 \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{2} \u001b[0m│\u001b[0m\n└\u001b[0m─────────────────────────\u001b[0m┴\u001b[0m────────────────────────────────\u001b[0m┴\u001b[0m──────────────────\u001b[0m┘\u001b[0m\n_.nrows = 366\n"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "cell_type": "code",
   "source": [
    "coerce!(horse, Count => Continuous);\n",
    "schema(horse)"
   ],
   "metadata": {},
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll correct the remaining truant entries manually:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "┌\u001b[0m─────────────────────────\u001b[0m┬\u001b[0m────────────────────────────────\u001b[0m┬\u001b[0m──────────────────\u001b[0m┐\u001b[0m\n│\u001b[0m\u001b[22m _.names                 \u001b[0m│\u001b[0m\u001b[22m _.types                        \u001b[0m│\u001b[0m\u001b[22m _.scitypes       \u001b[0m│\u001b[0m\n├\u001b[0m─────────────────────────\u001b[0m┼\u001b[0m────────────────────────────────\u001b[0m┼\u001b[0m──────────────────\u001b[0m┤\u001b[0m\n│\u001b[0m surgery                 \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m Multiclass{2}    \u001b[0m│\u001b[0m\n│\u001b[0m age                     \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m Multiclass{2}    \u001b[0m│\u001b[0m\n│\u001b[0m rectal_temperature      \u001b[0m│\u001b[0m Float64                        \u001b[0m│\u001b[0m Continuous       \u001b[0m│\u001b[0m\n│\u001b[0m pulse                   \u001b[0m│\u001b[0m Float64                        \u001b[0m│\u001b[0m Continuous       \u001b[0m│\u001b[0m\n│\u001b[0m respiratory_rate        \u001b[0m│\u001b[0m Float64                        \u001b[0m│\u001b[0m Continuous       \u001b[0m│\u001b[0m\n│\u001b[0m temperature_extremities \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{4} \u001b[0m│\u001b[0m\n│\u001b[0m mucous_membranes        \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m Multiclass{6}    \u001b[0m│\u001b[0m\n│\u001b[0m capillary_refill_time   \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m Multiclass{3}    \u001b[0m│\u001b[0m\n│\u001b[0m pain                    \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{5} \u001b[0m│\u001b[0m\n│\u001b[0m peristalsis             \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{4} \u001b[0m│\u001b[0m\n│\u001b[0m abdominal_distension    \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{4} \u001b[0m│\u001b[0m\n│\u001b[0m packed_cell_volume      \u001b[0m│\u001b[0m Float64                        \u001b[0m│\u001b[0m Continuous       \u001b[0m│\u001b[0m\n│\u001b[0m total_protein           \u001b[0m│\u001b[0m Float64                        \u001b[0m│\u001b[0m Continuous       \u001b[0m│\u001b[0m\n│\u001b[0m outcome                 \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m Multiclass{3}    \u001b[0m│\u001b[0m\n│\u001b[0m surgical_lesion         \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{2} \u001b[0m│\u001b[0m\n│\u001b[0m cp_data                 \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m Multiclass{2}    \u001b[0m│\u001b[0m\n└\u001b[0m─────────────────────────\u001b[0m┴\u001b[0m────────────────────────────────\u001b[0m┴\u001b[0m──────────────────\u001b[0m┘\u001b[0m\n_.nrows = 366\n"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "cell_type": "code",
   "source": [
    "coerce!(horse,\n",
    "        :surgery               => Multiclass,\n",
    "        :age                   => Multiclass,\n",
    "        :mucous_membranes      => Multiclass,\n",
    "        :capillary_refill_time => Multiclass,\n",
    "        :outcome               => Multiclass,\n",
    "        :cp_data               => Multiclass);\n",
    "schema(horse)"
   ],
   "metadata": {},
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Resources for Part 1\n",
    "\n",
    "- From the MLJ manual:\n",
    "   - [A preview of data type specification in\n",
    "  MLJ](https://alan-turing-institute.github.io/MLJ.jl/dev/getting_started/#A-preview-of-data-type-specification-in-MLJ-1)\n",
    "   - [Data containers and scientific types](https://alan-turing-institute.github.io/MLJ.jl/dev/getting_started/#Data-containers-and-scientific-types-1)\n",
    "   - [Working with Categorical Data](https://alan-turing-institute.github.io/MLJ.jl/dev/working_with_categorical_data/)\n",
    "- [Summary](https://alan-turing-institute.github.io/MLJScientificTypes.jl/dev/#Summary-of-the-MLJ-convention-1) of the MLJ convention for representing scientific types\n",
    "- [MLJScientificTypes.jl](https://alan-turing-institute.github.io/MLJScientificTypes.jl/dev/)\n",
    "- From Data Science Tutorials:\n",
    "    - [Data interpretation: Scientific Types](https://alan-turing-institute.github.io/DataScienceTutorials.jl/data/scitype/)\n",
    "    - [Horse colic data](https://alan-turing-institute.github.io/DataScienceTutorials.jl/end-to-end/horse/)\n",
    "- [UCI Horse Colic Data Set](http://archive.ics.uci.edu/ml/datasets/Horse+Colic)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exercises for Part 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ex 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Try to guess how each code snippet below will evaluate:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Count"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "cell_type": "code",
   "source": [
    "scitype(42)"
   ],
   "metadata": {},
   "execution_count": 25
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "AbstractArray{Textual,1}"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "cell_type": "code",
   "source": [
    "questions = [\"who\", \"why\", \"what\", \"when\"]\n",
    "scitype(questions)"
   ],
   "metadata": {},
   "execution_count": 26
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Textual"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "cell_type": "code",
   "source": [
    "elscitype(questions)"
   ],
   "metadata": {},
   "execution_count": 27
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Tuple{Continuous,Count,Textual}"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "cell_type": "code",
   "source": [
    "t = (3.141, 42, \"how\")\n",
    "scitype(t)"
   ],
   "metadata": {},
   "execution_count": 28
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2×3 Array{Float64,2}:\n 0.949666  0.648992  0.968531\n 0.657601  0.964264  0.621786"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "cell_type": "code",
   "source": [
    "A = rand(2, 3)"
   ],
   "metadata": {},
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "source": [
    "-"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "AbstractArray{Continuous,2}"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "cell_type": "code",
   "source": [
    "scitype(A)"
   ],
   "metadata": {},
   "execution_count": 30
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Continuous"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "cell_type": "code",
   "source": [
    "elscitype(A)"
   ],
   "metadata": {},
   "execution_count": 31
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2×3 SparseMatrixCSC{Float64,Int64} with 6 stored entries:\n  [1, 1]  =  0.949666\n  [2, 1]  =  0.657601\n  [1, 2]  =  0.648992\n  [2, 2]  =  0.964264\n  [1, 3]  =  0.968531\n  [2, 3]  =  0.621786"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "cell_type": "code",
   "source": [
    "using SparseArrays\n",
    "Asparse = sparse(A)"
   ],
   "metadata": {},
   "execution_count": 32
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "AbstractArray{Continuous,2}"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "cell_type": "code",
   "source": [
    "scitype(Asparse)"
   ],
   "metadata": {},
   "execution_count": 33
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2×3 CategoricalArray{Float64,2,UInt32}:\n 0.9496659122609439  0.648991635558477   0.9685312128025074\n 0.657600770969814   0.9642637988837086  0.6217855033748962"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "cell_type": "code",
   "source": [
    "using CategoricalArrays\n",
    "C1 = categorical(A)"
   ],
   "metadata": {},
   "execution_count": 34
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "AbstractArray{Multiclass{6},2}"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "cell_type": "code",
   "source": [
    "scitype(C1)"
   ],
   "metadata": {},
   "execution_count": 35
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Multiclass{6}"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "cell_type": "code",
   "source": [
    "elscitype(C1)"
   ],
   "metadata": {},
   "execution_count": 36
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "AbstractArray{OrderedFactor{6},2}"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "cell_type": "code",
   "source": [
    "C2 = categorical(A, ordered=true)\n",
    "scitype(C2)"
   ],
   "metadata": {},
   "execution_count": 37
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "AbstractArray{Union{Missing, Count},1}"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "cell_type": "code",
   "source": [
    "v = [1, 2, missing, 4]\n",
    "scitype(v)"
   ],
   "metadata": {},
   "execution_count": 38
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Union{Missing, Count}"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "cell_type": "code",
   "source": [
    "elscitype(v)"
   ],
   "metadata": {},
   "execution_count": 39
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "AbstractArray{Union{Missing, Count},1}"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "cell_type": "code",
   "source": [
    "scitype(v[1:2])"
   ],
   "metadata": {},
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "source": [
    "Can you guess at the general behaviour of\n",
    "`scitype` with respect to tuples, abstract arrays and missing\n",
    "values? The answers are\n",
    "[here](https://github.com/alan-turing-institute/ScientificTypes.jl#2-the-scitype-and-scitype-methods)\n",
    "(ignore \"Property 1\")."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ex 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Coerce the following vector to make MLJ recognize it as a vector of\n",
    "ordered factors (with an appropriate ordering):"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "7-element Array{Union{Missing, String},1}:\n \"good\"\n \"poor\"\n \"poor\"\n \"excellent\"\n missing\n \"good\"\n \"excellent\""
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "cell_type": "code",
   "source": [
    "quality = [\"good\", \"poor\", \"poor\", \"excellent\", missing, \"good\", \"excellent\"]"
   ],
   "metadata": {},
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ex 3 (fixing scitypes in a table)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fix the scitypes for the [House Prices in King\n",
    "County](https://mlr3gallery.mlr-org.com/posts/2020-01-30-house-prices-in-king-county/)\n",
    "dataset:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4×19 DataFrame. Omitted printing of 12 columns\n│ Row │ price    │ bedrooms │ bathrooms │ sqft_living │ sqft_lot │ floors  │ waterfront │\n│     │ \u001b[90mFloat64\u001b[39m  │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mInt64\u001b[39m       │ \u001b[90mInt64\u001b[39m    │ \u001b[90mFloat64\u001b[39m │ \u001b[90mInt64\u001b[39m      │\n├─────┼──────────┼──────────┼───────────┼─────────────┼──────────┼─────────┼────────────┤\n│ 1   │ 221900.0 │ 3        │ 1.0       │ 1180        │ 5650     │ 1.0     │ 0          │\n│ 2   │ 538000.0 │ 3        │ 2.25      │ 2570        │ 7242     │ 2.0     │ 0          │\n│ 3   │ 180000.0 │ 2        │ 1.0       │ 770         │ 10000    │ 1.0     │ 0          │\n│ 4   │ 604000.0 │ 4        │ 3.0       │ 1960        │ 5000     │ 1.0     │ 0          │",
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>price</th><th>bedrooms</th><th>bathrooms</th><th>sqft_living</th><th>sqft_lot</th><th>floors</th><th>waterfront</th><th>view</th><th>condition</th></tr><tr><th></th><th>Float64</th><th>Int64</th><th>Float64</th><th>Int64</th><th>Int64</th><th>Float64</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>4 rows × 19 columns (omitted printing of 10 columns)</p><tr><th>1</th><td>221900.0</td><td>3</td><td>1.0</td><td>1180</td><td>5650</td><td>1.0</td><td>0</td><td>0</td><td>3</td></tr><tr><th>2</th><td>538000.0</td><td>3</td><td>2.25</td><td>2570</td><td>7242</td><td>2.0</td><td>0</td><td>0</td><td>3</td></tr><tr><th>3</th><td>180000.0</td><td>2</td><td>1.0</td><td>770</td><td>10000</td><td>1.0</td><td>0</td><td>0</td><td>3</td></tr><tr><th>4</th><td>604000.0</td><td>4</td><td>3.0</td><td>1960</td><td>5000</td><td>1.0</td><td>0</td><td>0</td><td>5</td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "cell_type": "code",
   "source": [
    "file = CSV.File(joinpath(DIR, \"data\", \"house.csv\"));\n",
    "house = DataFrames.DataFrame(file); # convert to data frame without copying columns\n",
    "first(house, 4)"
   ],
   "metadata": {},
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "source": [
    "(Two features in the original data set have been deemed uninformative\n",
    "and dropped, namely `:id` and `:date`. The original feature\n",
    "`:yr_renovated` has been replaced by the `Bool` feature `is_renovated`.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 2: Selecting, Training and Evaluating Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Goals:**\n",
    "> 1. Search MLJ's database of model metadata to identify model candidates for a supervised learning task.\n",
    "> 2. Evaluate the performance of a model on a holdout set using basic `fit!`/`predict` workflow.\n",
    "> 3. Evaluate performance using other resampling strategies, such as cross-validation, in one line, using `evaluate!`\n",
    "> 4. Plot a \"learning curve\", to inspect performance as a function of some model hyper-parameter, such as an iteration parameter"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The \"Hello World!\" of machine learning is to classify Fisher's\n",
    "famous iris data set. This time, we'll grab the data from\n",
    "[OpenML](https://www.openml.org):"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4×5 DataFrame\n│ Row │ sepallength │ sepalwidth │ petallength │ petalwidth │ class       │\n│     │ \u001b[90mFloat64\u001b[39m     │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mFloat64\u001b[39m     │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mSubString…\u001b[39m  │\n├─────┼─────────────┼────────────┼─────────────┼────────────┼─────────────┤\n│ 1   │ 5.1         │ 3.5        │ 1.4         │ 0.2        │ Iris-setosa │\n│ 2   │ 4.9         │ 3.0        │ 1.4         │ 0.2        │ Iris-setosa │\n│ 3   │ 4.7         │ 3.2        │ 1.3         │ 0.2        │ Iris-setosa │\n│ 4   │ 4.6         │ 3.1        │ 1.5         │ 0.2        │ Iris-setosa │",
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>sepallength</th><th>sepalwidth</th><th>petallength</th><th>petalwidth</th><th>class</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>SubStri…</th></tr></thead><tbody><p>4 rows × 5 columns</p><tr><th>1</th><td>5.1</td><td>3.5</td><td>1.4</td><td>0.2</td><td>Iris-setosa</td></tr><tr><th>2</th><td>4.9</td><td>3.0</td><td>1.4</td><td>0.2</td><td>Iris-setosa</td></tr><tr><th>3</th><td>4.7</td><td>3.2</td><td>1.3</td><td>0.2</td><td>Iris-setosa</td></tr><tr><th>4</th><td>4.6</td><td>3.1</td><td>1.5</td><td>0.2</td><td>Iris-setosa</td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "cell_type": "code",
   "source": [
    "iris = OpenML.load(61); # a row table\n",
    "iris = DataFrames.DataFrame(iris);\n",
    "first(iris, 4)"
   ],
   "metadata": {},
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Goal.** To build and evaluate models for predicting the\n",
    "`:class` variable, given the four remaining measurement variables."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 1. Inspect and fix scientific types"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "┌\u001b[0m─────────────\u001b[0m┬\u001b[0m───────────────────\u001b[0m┬\u001b[0m────────────\u001b[0m┐\u001b[0m\n│\u001b[0m\u001b[22m _.names     \u001b[0m│\u001b[0m\u001b[22m _.types           \u001b[0m│\u001b[0m\u001b[22m _.scitypes \u001b[0m│\u001b[0m\n├\u001b[0m─────────────\u001b[0m┼\u001b[0m───────────────────\u001b[0m┼\u001b[0m────────────\u001b[0m┤\u001b[0m\n│\u001b[0m sepallength \u001b[0m│\u001b[0m Float64           \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m sepalwidth  \u001b[0m│\u001b[0m Float64           \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m petallength \u001b[0m│\u001b[0m Float64           \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m petalwidth  \u001b[0m│\u001b[0m Float64           \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m class       \u001b[0m│\u001b[0m SubString{String} \u001b[0m│\u001b[0m Textual    \u001b[0m│\u001b[0m\n└\u001b[0m─────────────\u001b[0m┴\u001b[0m───────────────────\u001b[0m┴\u001b[0m────────────\u001b[0m┘\u001b[0m\n_.nrows = 150\n"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "cell_type": "code",
   "source": [
    "schema(iris)"
   ],
   "metadata": {},
   "execution_count": 44
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "┌\u001b[0m─────────────\u001b[0m┬\u001b[0m─────────────────────────────────\u001b[0m┬\u001b[0m───────────────\u001b[0m┐\u001b[0m\n│\u001b[0m\u001b[22m _.names     \u001b[0m│\u001b[0m\u001b[22m _.types                         \u001b[0m│\u001b[0m\u001b[22m _.scitypes    \u001b[0m│\u001b[0m\n├\u001b[0m─────────────\u001b[0m┼\u001b[0m─────────────────────────────────\u001b[0m┼\u001b[0m───────────────\u001b[0m┤\u001b[0m\n│\u001b[0m sepallength \u001b[0m│\u001b[0m Float64                         \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n│\u001b[0m sepalwidth  \u001b[0m│\u001b[0m Float64                         \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n│\u001b[0m petallength \u001b[0m│\u001b[0m Float64                         \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n│\u001b[0m petalwidth  \u001b[0m│\u001b[0m Float64                         \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n│\u001b[0m class       \u001b[0m│\u001b[0m CategoricalValue{String,UInt32} \u001b[0m│\u001b[0m Multiclass{3} \u001b[0m│\u001b[0m\n└\u001b[0m─────────────\u001b[0m┴\u001b[0m─────────────────────────────────\u001b[0m┴\u001b[0m───────────────\u001b[0m┘\u001b[0m\n_.nrows = 150\n"
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "cell_type": "code",
   "source": [
    "coerce!(iris, :class => Multiclass);\n",
    "schema(iris)"
   ],
   "metadata": {},
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 2. Split data into input and target parts"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here's how we split the data into target and input features, which\n",
    "is needed for MLJ supervised models. We randomize the data at the\n",
    "same time:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "AbstractArray{Multiclass{3},1}"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "cell_type": "code",
   "source": [
    "y, X = unpack(iris, ==(:class), name->true; rng=123);\n",
    "scitype(y)"
   ],
   "metadata": {},
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "source": [
    "Do `?unpack` to learn more:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[36m  t1, t2, ...., tk = unnpack(table, f1, f2, ... fk; wrap_singles=false)\u001b[39m\n\n  Split any Tables.jl compatible \u001b[36mtable\u001b[39m into smaller tables (or vectors) \u001b[36mt1, t2, ..., tk\u001b[39m by\n  making selections \u001b[4mwithout replacement\u001b[24m from the column names defined by the filters \u001b[36mf1\u001b[39m,\n  \u001b[36mf2\u001b[39m, ..., \u001b[36mfk\u001b[39m. A \u001b[4mfilter\u001b[24m is any object \u001b[36mf\u001b[39m such that \u001b[36mf(name)\u001b[39m is \u001b[36mtrue\u001b[39m or \u001b[36mfalse\u001b[39m for each column\n  \u001b[36mname::Symbol\u001b[39m of \u001b[36mtable\u001b[39m.\n\n  Whenever a returned table contains a single column, it is converted to a vector unless\n  \u001b[36mwrap_singles=true\u001b[39m.\n\n  Scientific type conversions can be optionally specified (note semicolon):\n\n\u001b[36m  unpack(table, t...; wrap_singles=false, col1=>scitype1, col2=>scitype2, ... )\u001b[39m\n\n\u001b[1m  Example\u001b[22m\n\u001b[1m  –––––––––\u001b[22m\n\n\u001b[36m  julia> table = DataFrame(x=[1,2], y=['a', 'b'], z=[10.0, 20.0], w=[:A, :B])\u001b[39m\n\u001b[36m  julia> Z, XY = unpack(table, ==(:z), !=(:w);\u001b[39m\n\u001b[36m                 :x=>Continuous, :y=>Multiclass)\u001b[39m\n\u001b[36m  julia> XY\u001b[39m\n\u001b[36m  2×2 DataFrame\u001b[39m\n\u001b[36m  │ Row │ x       │ y            │\u001b[39m\n\u001b[36m  │     │ Float64 │ Categorical… │\u001b[39m\n\u001b[36m  ├─────┼─────────┼──────────────┤\u001b[39m\n\u001b[36m  │ 1   │ 1.0     │ 'a'          │\u001b[39m\n\u001b[36m  │ 2   │ 2.0     │ 'b'          │\u001b[39m\n\u001b[36m  \u001b[39m\n\u001b[36m  julia> Z\u001b[39m\n\u001b[36m  2-element Array{Float64,1}:\u001b[39m\n\u001b[36m   10.0\u001b[39m\n\u001b[36m   20.0\u001b[39m",
      "text/markdown": "```\nt1, t2, ...., tk = unnpack(table, f1, f2, ... fk; wrap_singles=false)\n```\n\nSplit any Tables.jl compatible `table` into smaller tables (or vectors) `t1, t2, ..., tk` by making selections *without replacement* from the column names defined by the filters `f1`, `f2`, ..., `fk`. A *filter* is any object `f` such that `f(name)` is `true` or `false` for each column `name::Symbol` of `table`.\n\nWhenever a returned table contains a single column, it is converted to a vector unless `wrap_singles=true`.\n\nScientific type conversions can be optionally specified (note semicolon):\n\n```\nunpack(table, t...; wrap_singles=false, col1=>scitype1, col2=>scitype2, ... )\n```\n\n### Example\n\n```\njulia> table = DataFrame(x=[1,2], y=['a', 'b'], z=[10.0, 20.0], w=[:A, :B])\njulia> Z, XY = unpack(table, ==(:z), !=(:w);\n               :x=>Continuous, :y=>Multiclass)\njulia> XY\n2×2 DataFrame\n│ Row │ x       │ y            │\n│     │ Float64 │ Categorical… │\n├─────┼─────────┼──────────────┤\n│ 1   │ 1.0     │ 'a'          │\n│ 2   │ 2.0     │ 'b'          │\n\njulia> Z\n2-element Array{Float64,1}:\n 10.0\n 20.0\n```\n"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "cell_type": "code",
   "source": [
    "@doc unpack"
   ],
   "metadata": {},
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "source": [
    "### On searching for a model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here's how to see *all* models (not immediately useful):"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "142-element Array{NamedTuple{(:name, :package_name, :is_supervised, :docstring, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :is_pure_julia, :is_wrapper, :load_path, :package_license, :package_url, :package_uuid, :prediction_type, :supports_online, :supports_weights, :input_scitype, :target_scitype, :output_scitype),T} where T<:Tuple,1}:\n (name = ARDRegressor, package_name = ScikitLearn, ... )\n (name = AdaBoostClassifier, package_name = ScikitLearn, ... )\n (name = AdaBoostRegressor, package_name = ScikitLearn, ... )\n (name = AdaBoostStumpClassifier, package_name = DecisionTree, ... )\n (name = AffinityPropagation, package_name = ScikitLearn, ... )\n (name = AgglomerativeClustering, package_name = ScikitLearn, ... )\n (name = BaggingClassifier, package_name = ScikitLearn, ... )\n (name = BaggingRegressor, package_name = ScikitLearn, ... )\n (name = BayesianLDA, package_name = MultivariateStats, ... )\n (name = BayesianLDA, package_name = ScikitLearn, ... )\n (name = BayesianQDA, package_name = ScikitLearn, ... )\n (name = BayesianRidgeRegressor, package_name = ScikitLearn, ... )\n (name = BayesianSubspaceLDA, package_name = MultivariateStats, ... )\n (name = BernoulliNBClassifier, package_name = ScikitLearn, ... )\n (name = Birch, package_name = ScikitLearn, ... )\n (name = ComplementNBClassifier, package_name = ScikitLearn, ... )\n (name = ConstantClassifier, package_name = MLJModels, ... )\n (name = ConstantRegressor, package_name = MLJModels, ... )\n (name = ContinuousEncoder, package_name = MLJModels, ... )\n (name = DBSCAN, package_name = ScikitLearn, ... )\n (name = DecisionTreeClassifier, package_name = DecisionTree, ... )\n (name = DecisionTreeRegressor, package_name = DecisionTree, ... )\n (name = DeterministicConstantClassifier, package_name = MLJModels, ... )\n (name = DeterministicConstantRegressor, package_name = MLJModels, ... )\n (name = DeterministicSurrogate, package_name = MLJBase, ... )\n (name = DummyClassifier, package_name = ScikitLearn, ... )\n ⋮\n (name = RidgeRegressor, package_name = MLJLinearModels, ... )\n (name = RidgeRegressor, package_name = MultivariateStats, ... )\n (name = RidgeRegressor, package_name = ScikitLearn, ... )\n (name = RobustRegressor, package_name = MLJLinearModels, ... )\n (name = SGDClassifier, package_name = ScikitLearn, ... )\n (name = SGDRegressor, package_name = ScikitLearn, ... )\n (name = SVC, package_name = LIBSVM, ... )\n (name = SVMClassifier, package_name = ScikitLearn, ... )\n (name = SVMLinearClassifier, package_name = ScikitLearn, ... )\n (name = SVMLinearRegressor, package_name = ScikitLearn, ... )\n (name = SVMNuClassifier, package_name = ScikitLearn, ... )\n (name = SVMNuRegressor, package_name = ScikitLearn, ... )\n (name = SVMRegressor, package_name = ScikitLearn, ... )\n (name = SpectralClustering, package_name = ScikitLearn, ... )\n (name = Standardizer, package_name = MLJModels, ... )\n (name = StaticSurrogate, package_name = MLJBase, ... )\n (name = SubspaceLDA, package_name = MultivariateStats, ... )\n (name = TheilSenRegressor, package_name = ScikitLearn, ... )\n (name = UnivariateBoxCoxTransformer, package_name = MLJModels, ... )\n (name = UnivariateDiscretizer, package_name = MLJModels, ... )\n (name = UnivariateStandardizer, package_name = MLJModels, ... )\n (name = UnsupervisedSurrogate, package_name = MLJBase, ... )\n (name = WrappedFunction, package_name = MLJBase, ... )\n (name = XGBoostClassifier, package_name = XGBoost, ... )\n (name = XGBoostCount, package_name = XGBoost, ... )\n (name = XGBoostRegressor, package_name = XGBoost, ... )"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "cell_type": "code",
   "source": [
    "kitchen_sink = models()"
   ],
   "metadata": {},
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "source": [
    "Each entry contains metadata for a model whose defining code is not yet loaded:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[35mAdaBoost ensemble regression.\u001b[39m\n\u001b[35m→ based on [ScikitLearn](https://github.com/cstjean/ScikitLearn.jl).\u001b[39m\n\u001b[35m→ do `@load AdaBoostRegressor pkg=\"ScikitLearn\"` to use the model.\u001b[39m\n\u001b[35m→ do `?AdaBoostRegressor` for documentation.\u001b[39m\n(name = \"AdaBoostRegressor\",\n package_name = \"ScikitLearn\",\n is_supervised = true,\n docstring = \"AdaBoost ensemble regression.\\n→ based on [ScikitLearn](https://github.com/cstjean/ScikitLearn.jl).\\n→ do `@load AdaBoostRegressor pkg=\\\"ScikitLearn\\\"` to use the model.\\n→ do `?AdaBoostRegressor` for documentation.\",\n hyperparameter_ranges = (nothing, nothing, nothing, nothing, nothing),\n hyperparameter_types = (\"Any\", \"Int64\", \"Float64\", \"String\", \"Any\"),\n hyperparameters = (:base_estimator, :n_estimators, :learning_rate, :loss, :random_state),\n implemented_methods = [:clean!, :fit, :fitted_params, :predict],\n is_pure_julia = false,\n is_wrapper = true,\n load_path = \"MLJScikitLearnInterface.AdaBoostRegressor\",\n package_license = \"BSD\",\n package_url = \"https://github.com/cstjean/ScikitLearn.jl\",\n package_uuid = \"3646fa90-6ef7-5e7e-9f22-8aca16db6324\",\n prediction_type = :deterministic,\n supports_online = false,\n supports_weights = false,\n input_scitype = Table{_s23} where _s23<:(AbstractArray{_s25,1} where _s25<:Continuous),\n target_scitype = AbstractArray{Continuous,1},\n output_scitype = Unknown,)"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "cell_type": "code",
   "source": [
    "meta = kitchen_sink[3]"
   ],
   "metadata": {},
   "execution_count": 49
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "AbstractArray{Continuous,1}"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "cell_type": "code",
   "source": [
    "targetscitype = meta.target_scitype"
   ],
   "metadata": {},
   "execution_count": 50
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "false"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "cell_type": "code",
   "source": [
    "scitype(y) <: targetscitype"
   ],
   "metadata": {},
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "source": [
    "So this model won't do. Let's  find all pure julia classifiers:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "16-element Array{NamedTuple{(:name, :package_name, :is_supervised, :docstring, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :is_pure_julia, :is_wrapper, :load_path, :package_license, :package_url, :package_uuid, :prediction_type, :supports_online, :supports_weights, :input_scitype, :target_scitype, :output_scitype),T} where T<:Tuple,1}:\n (name = AdaBoostStumpClassifier, package_name = DecisionTree, ... )\n (name = BayesianLDA, package_name = MultivariateStats, ... )\n (name = BayesianSubspaceLDA, package_name = MultivariateStats, ... )\n (name = ConstantClassifier, package_name = MLJModels, ... )\n (name = DecisionTreeClassifier, package_name = DecisionTree, ... )\n (name = DeterministicConstantClassifier, package_name = MLJModels, ... )\n (name = EvoTreeClassifier, package_name = EvoTrees, ... )\n (name = GaussianNBClassifier, package_name = NaiveBayes, ... )\n (name = KNNClassifier, package_name = NearestNeighbors, ... )\n (name = LDA, package_name = MultivariateStats, ... )\n (name = LogisticClassifier, package_name = MLJLinearModels, ... )\n (name = MultinomialClassifier, package_name = MLJLinearModels, ... )\n (name = MultinomialNBClassifier, package_name = NaiveBayes, ... )\n (name = NeuralNetworkClassifier, package_name = MLJFlux, ... )\n (name = RandomForestClassifier, package_name = DecisionTree, ... )\n (name = SubspaceLDA, package_name = MultivariateStats, ... )"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "cell_type": "code",
   "source": [
    "filt(meta) = AbstractVector{Finite} <: meta.target_scitype &&\n",
    "        meta.is_pure_julia\n",
    "models(filt)"
   ],
   "metadata": {},
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "source": [
    "Find all models with \"Classifier\" in `name` (or `docstring`):"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "39-element Array{NamedTuple{(:name, :package_name, :is_supervised, :docstring, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :is_pure_julia, :is_wrapper, :load_path, :package_license, :package_url, :package_uuid, :prediction_type, :supports_online, :supports_weights, :input_scitype, :target_scitype, :output_scitype),T} where T<:Tuple,1}:\n (name = AdaBoostClassifier, package_name = ScikitLearn, ... )\n (name = AdaBoostStumpClassifier, package_name = DecisionTree, ... )\n (name = BaggingClassifier, package_name = ScikitLearn, ... )\n (name = BernoulliNBClassifier, package_name = ScikitLearn, ... )\n (name = ComplementNBClassifier, package_name = ScikitLearn, ... )\n (name = ConstantClassifier, package_name = MLJModels, ... )\n (name = DecisionTreeClassifier, package_name = DecisionTree, ... )\n (name = DeterministicConstantClassifier, package_name = MLJModels, ... )\n (name = DummyClassifier, package_name = ScikitLearn, ... )\n (name = EvoTreeClassifier, package_name = EvoTrees, ... )\n (name = ExtraTreesClassifier, package_name = ScikitLearn, ... )\n (name = GaussianNBClassifier, package_name = NaiveBayes, ... )\n (name = GaussianNBClassifier, package_name = ScikitLearn, ... )\n (name = GaussianProcessClassifier, package_name = ScikitLearn, ... )\n (name = GradientBoostingClassifier, package_name = ScikitLearn, ... )\n (name = ImageClassifier, package_name = MLJFlux, ... )\n (name = KNNClassifier, package_name = NearestNeighbors, ... )\n (name = KNeighborsClassifier, package_name = ScikitLearn, ... )\n (name = LGBMClassifier, package_name = LightGBM, ... )\n (name = LinearBinaryClassifier, package_name = GLM, ... )\n (name = LogisticCVClassifier, package_name = ScikitLearn, ... )\n (name = LogisticClassifier, package_name = MLJLinearModels, ... )\n (name = LogisticClassifier, package_name = ScikitLearn, ... )\n (name = MultinomialClassifier, package_name = MLJLinearModels, ... )\n (name = MultinomialNBClassifier, package_name = NaiveBayes, ... )\n (name = MultinomialNBClassifier, package_name = ScikitLearn, ... )\n (name = NeuralNetworkClassifier, package_name = MLJFlux, ... )\n (name = PassiveAggressiveClassifier, package_name = ScikitLearn, ... )\n (name = PerceptronClassifier, package_name = ScikitLearn, ... )\n (name = ProbabilisticSGDClassifier, package_name = ScikitLearn, ... )\n (name = RandomForestClassifier, package_name = DecisionTree, ... )\n (name = RandomForestClassifier, package_name = ScikitLearn, ... )\n (name = RidgeCVClassifier, package_name = ScikitLearn, ... )\n (name = RidgeClassifier, package_name = ScikitLearn, ... )\n (name = SGDClassifier, package_name = ScikitLearn, ... )\n (name = SVMClassifier, package_name = ScikitLearn, ... )\n (name = SVMLinearClassifier, package_name = ScikitLearn, ... )\n (name = SVMNuClassifier, package_name = ScikitLearn, ... )\n (name = XGBoostClassifier, package_name = XGBoost, ... )"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "cell_type": "code",
   "source": [
    "models(\"Classifier\")"
   ],
   "metadata": {},
   "execution_count": 53
  },
  {
   "cell_type": "markdown",
   "source": [
    "Find all (supervised) models that match my data!"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "42-element Array{NamedTuple{(:name, :package_name, :is_supervised, :docstring, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :is_pure_julia, :is_wrapper, :load_path, :package_license, :package_url, :package_uuid, :prediction_type, :supports_online, :supports_weights, :input_scitype, :target_scitype, :output_scitype),T} where T<:Tuple,1}:\n (name = AdaBoostClassifier, package_name = ScikitLearn, ... )\n (name = AdaBoostStumpClassifier, package_name = DecisionTree, ... )\n (name = BaggingClassifier, package_name = ScikitLearn, ... )\n (name = BayesianLDA, package_name = MultivariateStats, ... )\n (name = BayesianLDA, package_name = ScikitLearn, ... )\n (name = BayesianQDA, package_name = ScikitLearn, ... )\n (name = BayesianSubspaceLDA, package_name = MultivariateStats, ... )\n (name = ConstantClassifier, package_name = MLJModels, ... )\n (name = DecisionTreeClassifier, package_name = DecisionTree, ... )\n (name = DeterministicConstantClassifier, package_name = MLJModels, ... )\n (name = DummyClassifier, package_name = ScikitLearn, ... )\n (name = EvoTreeClassifier, package_name = EvoTrees, ... )\n (name = ExtraTreesClassifier, package_name = ScikitLearn, ... )\n (name = GaussianNBClassifier, package_name = NaiveBayes, ... )\n (name = GaussianNBClassifier, package_name = ScikitLearn, ... )\n (name = GaussianProcessClassifier, package_name = ScikitLearn, ... )\n (name = GradientBoostingClassifier, package_name = ScikitLearn, ... )\n (name = KNNClassifier, package_name = NearestNeighbors, ... )\n (name = KNeighborsClassifier, package_name = ScikitLearn, ... )\n (name = LDA, package_name = MultivariateStats, ... )\n (name = LGBMClassifier, package_name = LightGBM, ... )\n (name = LinearSVC, package_name = LIBSVM, ... )\n (name = LogisticCVClassifier, package_name = ScikitLearn, ... )\n (name = LogisticClassifier, package_name = MLJLinearModels, ... )\n (name = LogisticClassifier, package_name = ScikitLearn, ... )\n (name = MultinomialClassifier, package_name = MLJLinearModels, ... )\n (name = NeuralNetworkClassifier, package_name = MLJFlux, ... )\n (name = NuSVC, package_name = LIBSVM, ... )\n (name = PassiveAggressiveClassifier, package_name = ScikitLearn, ... )\n (name = PerceptronClassifier, package_name = ScikitLearn, ... )\n (name = ProbabilisticSGDClassifier, package_name = ScikitLearn, ... )\n (name = RandomForestClassifier, package_name = DecisionTree, ... )\n (name = RandomForestClassifier, package_name = ScikitLearn, ... )\n (name = RidgeCVClassifier, package_name = ScikitLearn, ... )\n (name = RidgeClassifier, package_name = ScikitLearn, ... )\n (name = SGDClassifier, package_name = ScikitLearn, ... )\n (name = SVC, package_name = LIBSVM, ... )\n (name = SVMClassifier, package_name = ScikitLearn, ... )\n (name = SVMLinearClassifier, package_name = ScikitLearn, ... )\n (name = SVMNuClassifier, package_name = ScikitLearn, ... )\n (name = SubspaceLDA, package_name = MultivariateStats, ... )\n (name = XGBoostClassifier, package_name = XGBoost, ... )"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "cell_type": "code",
   "source": [
    "models(matching(X, y))"
   ],
   "metadata": {},
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 3. Select and instantiate a model"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "NeuralNetworkClassifier(\n    builder = Short(\n            n_hidden = 0,\n            dropout = 0.5,\n            σ = NNlib.σ),\n    finaliser = NNlib.softmax,\n    optimiser = Flux.Optimise.ADAM(0.001, (0.9, 0.999), IdDict{Any,Any}()),\n    loss = Flux.crossentropy,\n    epochs = 10,\n    batch_size = 1,\n    lambda = 0.0,\n    alpha = 0.0,\n    optimiser_changes_trigger_retraining = false)\u001b[34m @631\u001b[39m"
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "cell_type": "code",
   "source": [
    "model = @load NeuralNetworkClassifier"
   ],
   "metadata": {},
   "execution_count": 55
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[35mA neural network model for making probabilistic predictions of a `Mutliclass` or `OrderedFactor` target, given a table of `Continuous` features. \u001b[39m\n\u001b[35m→ based on [MLJFlux](https://github.com/alan-turing-institute/MLJFlux.jl).\u001b[39m\n\u001b[35m→ do `@load NeuralNetworkClassifier pkg=\"MLJFlux\"` to use the model.\u001b[39m\n\u001b[35m→ do `?NeuralNetworkClassifier` for documentation.\u001b[39m\n(name = \"NeuralNetworkClassifier\",\n package_name = \"MLJFlux\",\n is_supervised = true,\n docstring = \"A neural network model for making probabilistic predictions of a `Mutliclass` or `OrderedFactor` target, given a table of `Continuous` features. \\n→ based on [MLJFlux](https://github.com/alan-turing-institute/MLJFlux.jl).\\n→ do `@load NeuralNetworkClassifier pkg=\\\"MLJFlux\\\"` to use the model.\\n→ do `?NeuralNetworkClassifier` for documentation.\",\n hyperparameter_ranges = (nothing, nothing, nothing, nothing, nothing, nothing, nothing, nothing, nothing),\n hyperparameter_types = (\"MLJFlux.Short\", \"typeof(NNlib.softmax)\", \"Flux.Optimise.ADAM\", \"typeof(Flux.crossentropy)\", \"Int64\", \"Int64\", \"Float64\", \"Float64\", \"Bool\"),\n hyperparameters = (:builder, :finaliser, :optimiser, :loss, :epochs, :batch_size, :lambda, :alpha, :optimiser_changes_trigger_retraining),\n implemented_methods = Any[],\n is_pure_julia = true,\n is_wrapper = false,\n load_path = \"MLJFlux.NeuralNetworkClassifier\",\n package_license = \"MIT\",\n package_url = \"https://github.com/alan-turing-institute/MLJFlux.jl\",\n package_uuid = \"094fc8d1-fd35-5302-93ea-dabda2abf845\",\n prediction_type = :probabilistic,\n supports_online = false,\n supports_weights = false,\n input_scitype = Table{#s23} where #s23<:(AbstractArray{#s25,1} where #s25<:Continuous),\n target_scitype = AbstractArray{#s38,1} where #s38<:Finite,\n output_scitype = Unknown,)"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "cell_type": "code",
   "source": [
    "info(model)"
   ],
   "metadata": {},
   "execution_count": 56
  },
  {
   "cell_type": "markdown",
   "source": [
    "In MLJ a *model* is just a struct containing hyper-parameters, and\n",
    "that's all. A model does not store *learned* parameters. Models are\n",
    "mutable:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "12"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "cell_type": "code",
   "source": [
    "model.epochs = 12"
   ],
   "metadata": {},
   "execution_count": 57
  },
  {
   "cell_type": "markdown",
   "source": [
    "And all models have a key-word constructor that works once `@load`\n",
    "has been performed:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "true"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "cell_type": "code",
   "source": [
    "NeuralNetworkClassifier(epochs=12) == model"
   ],
   "metadata": {},
   "execution_count": 58
  },
  {
   "cell_type": "markdown",
   "source": [
    "### On fitting, predicting, and inspecting models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In MLJ a model and training/validation data are typically bound\n",
    "together in a machine:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34mMachine{NeuralNetworkClassifier{Short,…}} @005\u001b[39m trained 0 times.\n  args: \n    1:\t\u001b[34mSource @273\u001b[39m ⏎ `Table{AbstractArray{Continuous,1}}`\n    2:\t\u001b[34mSource @347\u001b[39m ⏎ `AbstractArray{Multiclass{3},1}`\n"
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "cell_type": "code",
   "source": [
    "mach = machine(model, X, y)"
   ],
   "metadata": {},
   "execution_count": 59
  },
  {
   "cell_type": "markdown",
   "source": [
    "A machine stores *learned* parameters, among other things. We'll\n",
    "train this machine on 70% of the data and evaluate on a 30% holdout\n",
    "set. Let's start by dividing all row indices into `train` and `test`\n",
    "subsets:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  96, 97, 98, 99, 100, 101, 102, 103, 104, 105], [106, 107, 108, 109, 110, 111, 112, 113, 114, 115  …  141, 142, 143, 144, 145, 146, 147, 148, 149, 150])"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "cell_type": "code",
   "source": [
    "train, test = partition(eachindex(y), 0.7)"
   ],
   "metadata": {},
   "execution_count": 60
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{NeuralNetworkClassifier{Short,…}} @005\u001b[39m.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:317\n",
      "┌ Info: Loss is 1.132\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 1.091\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 1.062\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 1.042\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 1.024\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 1.013\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 1.003\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.9917\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.9854\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.9713\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.9613\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.953\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34mMachine{NeuralNetworkClassifier{Short,…}} @005\u001b[39m trained 1 time.\n  args: \n    1:\t\u001b[34mSource @273\u001b[39m ⏎ `Table{AbstractArray{Continuous,1}}`\n    2:\t\u001b[34mSource @347\u001b[39m ⏎ `AbstractArray{Multiclass{3},1}`\n"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "cell_type": "code",
   "source": [
    "fit!(mach, rows=train, verbosity=2)"
   ],
   "metadata": {},
   "execution_count": 61
  },
  {
   "cell_type": "markdown",
   "source": [
    "After training, one can inspect the learned parameters:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(chain = Chain(Chain(Dense(4, 3, σ), Dropout(0.5), Dense(3, 3)), softmax),)"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "cell_type": "code",
   "source": [
    "fitted_params(mach)"
   ],
   "metadata": {},
   "execution_count": 62
  },
  {
   "cell_type": "markdown",
   "source": [
    "Everything else the user might be interested in is accessed from the\n",
    "training *report*:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(training_losses = Any[1.1318434f0, 1.0909344f0, 1.0619767f0, 1.0417976f0, 1.024498f0, 1.0133653f0, 1.0034266f0, 0.99168724f0, 0.98537177f0, 0.97130626f0, 0.96130794f0, 0.9529781f0],)"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "cell_type": "code",
   "source": [
    "report(mach)"
   ],
   "metadata": {},
   "execution_count": 63
  },
  {
   "cell_type": "markdown",
   "source": [
    "Machines remember the last set of hyper-parameters used during fit,\n",
    "which, in the case of iterative models, allows for a warm restart of\n",
    "computations in the case that only the iteration parameter is\n",
    "increased:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Info: Updating \u001b[34mMachine{NeuralNetworkClassifier{Short,…}} @005\u001b[39m.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:318\n",
      "┌ Info: Loss is 0.938\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.9288\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.9171\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.9071\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34mMachine{NeuralNetworkClassifier{Short,…}} @005\u001b[39m trained 2 times.\n  args: \n    1:\t\u001b[34mSource @273\u001b[39m ⏎ `Table{AbstractArray{Continuous,1}}`\n    2:\t\u001b[34mSource @347\u001b[39m ⏎ `AbstractArray{Multiclass{3},1}`\n"
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "cell_type": "code",
   "source": [
    "model.epochs = model.epochs + 4\n",
    "fit!(mach, rows=train, verbosity=2)"
   ],
   "metadata": {},
   "execution_count": 64
  },
  {
   "cell_type": "markdown",
   "source": [
    "By default (for this particular model) we can also increase\n",
    "`:learning_rate` without triggering a cold restart:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Info: Updating \u001b[34mMachine{NeuralNetworkClassifier{Short,…}} @005\u001b[39m.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:318\n",
      "┌ Info: Loss is 0.8051\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.7163\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.6627\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.5915\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34mMachine{NeuralNetworkClassifier{Short,…}} @005\u001b[39m trained 3 times.\n  args: \n    1:\t\u001b[34mSource @273\u001b[39m ⏎ `Table{AbstractArray{Continuous,1}}`\n    2:\t\u001b[34mSource @347\u001b[39m ⏎ `AbstractArray{Multiclass{3},1}`\n"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "cell_type": "code",
   "source": [
    "model.epochs = model.epochs + 4\n",
    "model.optimiser.eta = 10*model.optimiser.eta\n",
    "fit!(mach, rows=train, verbosity=2)"
   ],
   "metadata": {},
   "execution_count": 65
  },
  {
   "cell_type": "markdown",
   "source": [
    "However, change any other parameter and training will restart from\n",
    "scratch:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Info: Updating \u001b[34mMachine{NeuralNetworkClassifier{Short,…}} @005\u001b[39m.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:318\n",
      "┌ Info: Loss is 1.016\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.8518\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.766\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.6894\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.6453\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.6232\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.5906\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.5693\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.5476\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.5209\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.5197\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.5141\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.4893\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.5043\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.4634\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.4649\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.4881\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.4636\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.4555\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n",
      "┌ Info: Loss is 0.4256\n",
      "└ @ MLJFlux /Users/anthony/.julia/packages/MLJFlux/HxJNU/src/core.jl:95\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34mMachine{NeuralNetworkClassifier{Short,…}} @005\u001b[39m trained 4 times.\n  args: \n    1:\t\u001b[34mSource @273\u001b[39m ⏎ `Table{AbstractArray{Continuous,1}}`\n    2:\t\u001b[34mSource @347\u001b[39m ⏎ `AbstractArray{Multiclass{3},1}`\n"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "cell_type": "code",
   "source": [
    "model.lambda = 0.001\n",
    "fit!(mach, rows=train, verbosity=2)"
   ],
   "metadata": {},
   "execution_count": 66
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's train silently for a total of 50 epochs, and look at a prediction:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Info: Updating \u001b[34mMachine{NeuralNetworkClassifier{Short,…}} @005\u001b[39m.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:318\n",
      "\rOptimising neural net:  3%[>                        ]  ETA: 0:00:00\u001b[K\rOptimising neural net:  6%[=>                       ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 10%[==>                      ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 13%[===>                     ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 16%[====>                    ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 19%[====>                    ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 23%[=====>                   ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 26%[======>                  ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 29%[=======>                 ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 32%[========>                ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 35%[========>                ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 39%[=========>               ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 42%[==========>              ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 45%[===========>             ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 48%[============>            ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 52%[============>            ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 55%[=============>           ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 58%[==============>          ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 61%[===============>         ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 65%[================>        ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 68%[================>        ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 71%[=================>       ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 74%[==================>      ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 77%[===================>     ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 81%[====================>    ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 84%[====================>    ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 87%[=====================>   ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 90%[======================>  ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 94%[=======================> ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 97%[========================>]  ETA: 0:00:00\u001b[K\rOptimising neural net:100%[=========================] Time: 0:00:00\u001b[K\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "UnivariateFinite{Multiclass{3}}(Iris-setosa=>0.0607, Iris-versicolor=>0.559, Iris-virginica=>0.38)"
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "cell_type": "code",
   "source": [
    "model.epochs = 50\n",
    "fit!(mach, rows=train)\n",
    "yhat = predict(mach, X[test,:]); # or predict(mach, rows=test)\n",
    "yhat[1]"
   ],
   "metadata": {},
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "source": [
    "What's going on here?"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": ":probabilistic"
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "cell_type": "code",
   "source": [
    "info(model).prediction_type"
   ],
   "metadata": {},
   "execution_count": 68
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Important**:\n",
    "- In MLJ, a model that can predict probabilities (and not just point values) will do so by default. (These models have supertype `Proababilistic`, while point-estimate predictors have supertype `Deterministic`.)\n",
    "- For most probabilistic predictors, the predicted object is a `Distributions.Distribution` object, supporting the `Distributions.jl` [API](https://juliastats.org/Distributions.jl/latest/extends/#Create-a-Distribution-1) for such objects. In particular, the methods `rand`,  `pdf`, `mode`, `median` and `mean` will apply, where appropriate."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, to obtain the probability of \"Iris-virginica\" in the first test\n",
    "prediction, we do"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.38038898f0"
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "cell_type": "code",
   "source": [
    "pdf(yhat[1], \"Iris-virginica\")"
   ],
   "metadata": {},
   "execution_count": 69
  },
  {
   "cell_type": "markdown",
   "source": [
    "To get the most likely observation, we do"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "CategoricalValue{String,UInt32} \"Iris-versicolor\""
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "cell_type": "code",
   "source": [
    "mode(yhat[1])"
   ],
   "metadata": {},
   "execution_count": 70
  },
  {
   "cell_type": "markdown",
   "source": [
    "These can be broadcast over multiple predictions in the usual way:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4-element Array{Float32,1}:\n 0.55894643\n 0.3722597\n 0.015246802\n 0.3320612"
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "cell_type": "code",
   "source": [
    "broadcast(pdf, yhat[1:4], \"Iris-versicolor\")"
   ],
   "metadata": {},
   "execution_count": 71
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4-element CategoricalArray{String,1,UInt32}:\n \"Iris-versicolor\"\n \"Iris-virginica\"\n \"Iris-setosa\"\n \"Iris-virginica\""
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "cell_type": "code",
   "source": [
    "mode.(yhat[1:4])"
   ],
   "metadata": {},
   "execution_count": 72
  },
  {
   "cell_type": "markdown",
   "source": [
    "Or, alternatively, you can use the `predict_mode` operation instead\n",
    "of `predict`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4-element CategoricalArray{String,1,UInt32}:\n \"Iris-versicolor\"\n \"Iris-virginica\"\n \"Iris-setosa\"\n \"Iris-virginica\""
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "cell_type": "code",
   "source": [
    "predict_mode(mach, X[test,:])[1:4] # or predict_mode(mach, rows=test)[1:4]"
   ],
   "metadata": {},
   "execution_count": 73
  },
  {
   "cell_type": "markdown",
   "source": [
    "For a more conventional matrix of probabilities you can do this:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4×3 Array{Float32,2}:\n 0.0606645  0.558946   0.380389\n 0.0330928  0.37226    0.594648\n 0.984753   0.0152468  5.52088f-14\n 0.0282612  0.332061   0.639678"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "cell_type": "code",
   "source": [
    "L = levels(y)\n",
    "pdf(yhat, L)[1:4, :]"
   ],
   "metadata": {},
   "execution_count": 74
  },
  {
   "cell_type": "markdown",
   "source": [
    "However, in a typical MLJ workflow, this is not as useful as you\n",
    "might imagine. In particular, all probablistic performance measures\n",
    "in MLJ expect distribution objects in their first slot:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.37720057f0"
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "cell_type": "code",
   "source": [
    "cross_entropy(yhat, y[test]) |> mean"
   ],
   "metadata": {},
   "execution_count": 75
  },
  {
   "cell_type": "markdown",
   "source": [
    "To apply a deterministic measure, we first need to obtain point-estimates:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.13333333333333333"
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "cell_type": "code",
   "source": [
    "misclassification_rate(mode.(yhat), y[test])"
   ],
   "metadata": {},
   "execution_count": 76
  },
  {
   "cell_type": "markdown",
   "source": [
    "We note in passing that there is also a search tool for measures\n",
    "analogous to `models`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "6-element Array{NamedTuple{(:name, :target_scitype, :supports_weights, :prediction_type, :orientation, :reports_each_observation, :aggregation, :is_feature_dependent, :docstring, :distribution_type),T} where T<:Tuple,1}:\n (name = accuracy, ...)\n (name = balanced_accuracy, ...)\n (name = cross_entropy, ...)\n (name = misclassification_rate, ...)\n (name = BrierScore{UnivariateFinite}, ...)\n (name = confusion_matrix, ...)"
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "cell_type": "code",
   "source": [
    "measures(matching(y))"
   ],
   "metadata": {},
   "execution_count": 77
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 4. Evaluate the model performance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Naturally, MLJ provides boilerplate code for carrying out a model\n",
    "evaluation with a lot less fuss. Let's repeat the performance\n",
    "evaluation above and add an extra measure, `brier_score`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "┌\u001b[0m──────────────────────────────\u001b[0m┬\u001b[0m───────────────\u001b[0m┬\u001b[0m─────────────────\u001b[0m┐\u001b[0m\n│\u001b[0m\u001b[22m _.measure                    \u001b[0m│\u001b[0m\u001b[22m _.measurement \u001b[0m│\u001b[0m\u001b[22m _.per_fold      \u001b[0m│\u001b[0m\n├\u001b[0m──────────────────────────────\u001b[0m┼\u001b[0m───────────────\u001b[0m┼\u001b[0m─────────────────\u001b[0m┤\u001b[0m\n│\u001b[0m cross_entropy                \u001b[0m│\u001b[0m 0.377         \u001b[0m│\u001b[0m Float32[0.377]  \u001b[0m│\u001b[0m\n│\u001b[0m BrierScore{UnivariateFinite} \u001b[0m│\u001b[0m -0.227        \u001b[0m│\u001b[0m Float32[-0.227] \u001b[0m│\u001b[0m\n└\u001b[0m──────────────────────────────\u001b[0m┴\u001b[0m───────────────\u001b[0m┴\u001b[0m─────────────────\u001b[0m┘\u001b[0m\n_.per_observation = [[[0.582, 0.988, ..., 0.0132]], [[-0.343, -0.749, ..., -0.000345]]]\n"
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "cell_type": "code",
   "source": [
    "evaluate!(mach, resampling=Holdout(fraction_train=0.7),\n",
    "          measures=[cross_entropy, brier_score])"
   ],
   "metadata": {},
   "execution_count": 78
  },
  {
   "cell_type": "markdown",
   "source": [
    "Or applying cross-validation instead:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\rEvaluating over 6 folds:  17%[====>                    ]  ETA: 0:00:03\u001b[K\rEvaluating over 6 folds:  33%[========>                ]  ETA: 0:00:03\u001b[K\rEvaluating over 6 folds:  50%[============>            ]  ETA: 0:00:02\u001b[K\rEvaluating over 6 folds:  67%[================>        ]  ETA: 0:00:01\u001b[K\rEvaluating over 6 folds:  83%[====================>    ]  ETA: 0:00:01\u001b[K\rEvaluating over 6 folds: 100%[=========================] Time: 0:00:04\u001b[K\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "┌\u001b[0m──────────────────────────────\u001b[0m┬\u001b[0m───────────────\u001b[0m┬\u001b[0m────────────────────────────────────────────────────────\u001b[0m┐\u001b[0m\n│\u001b[0m\u001b[22m _.measure                    \u001b[0m│\u001b[0m\u001b[22m _.measurement \u001b[0m│\u001b[0m\u001b[22m _.per_fold                                             \u001b[0m│\u001b[0m\n├\u001b[0m──────────────────────────────\u001b[0m┼\u001b[0m───────────────\u001b[0m┼\u001b[0m────────────────────────────────────────────────────────\u001b[0m┤\u001b[0m\n│\u001b[0m cross_entropy                \u001b[0m│\u001b[0m 0.277         \u001b[0m│\u001b[0m Float32[0.28, 0.212, 0.287, 0.305, 0.349, 0.23]        \u001b[0m│\u001b[0m\n│\u001b[0m BrierScore{UnivariateFinite} \u001b[0m│\u001b[0m -0.139        \u001b[0m│\u001b[0m Float32[-0.128, -0.101, -0.13, -0.168, -0.195, -0.112] \u001b[0m│\u001b[0m\n└\u001b[0m──────────────────────────────\u001b[0m┴\u001b[0m───────────────\u001b[0m┴\u001b[0m────────────────────────────────────────────────────────\u001b[0m┘\u001b[0m\n_.per_observation = [[[0.262, 0.281, ..., 0.146], [0.0218, 0.474, ..., 0.0206], [0.136, 0.369, ..., 0.154], [0.00183, 0.48, ..., 0.00381], [0.35, 0.392, ..., 0.658], [0.00752, 0.352, ..., 0.00503]], [[-0.106, -0.103, ..., -0.0367], [-0.000932, -0.253, ..., -0.000829], [-0.0325, -0.178, ..., -0.0408], [-6.68e-6, -0.271, ..., -2.9e-5], [-0.136, -0.158, ..., -0.429], [-0.000112, -0.135, ..., -5.03e-5]]]\n"
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "cell_type": "code",
   "source": [
    "evaluate!(mach, resampling=CV(nfolds=6),\n",
    "          measures=[cross_entropy, brier_score])"
   ],
   "metadata": {},
   "execution_count": 79
  },
  {
   "cell_type": "markdown",
   "source": [
    "Or, Monte-Carlo cross-validation (cross-validation repeated\n",
    "randomizied folds)"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\rEvaluating over 18 folds:   6%[=>                       ]  ETA: 0:00:12\u001b[K\rEvaluating over 18 folds:  11%[==>                      ]  ETA: 0:00:11\u001b[K\rEvaluating over 18 folds:  17%[====>                    ]  ETA: 0:00:10\u001b[K\rEvaluating over 18 folds:  22%[=====>                   ]  ETA: 0:00:10\u001b[K\rEvaluating over 18 folds:  28%[======>                  ]  ETA: 0:00:09\u001b[K\rEvaluating over 18 folds:  33%[========>                ]  ETA: 0:00:08\u001b[K\rEvaluating over 18 folds:  39%[=========>               ]  ETA: 0:00:08\u001b[K\rEvaluating over 18 folds:  44%[===========>             ]  ETA: 0:00:07\u001b[K\rEvaluating over 18 folds:  50%[============>            ]  ETA: 0:00:06\u001b[K\rEvaluating over 18 folds:  56%[=============>           ]  ETA: 0:00:06\u001b[K\rEvaluating over 18 folds:  61%[===============>         ]  ETA: 0:00:05\u001b[K\rEvaluating over 18 folds:  67%[================>        ]  ETA: 0:00:04\u001b[K\rEvaluating over 18 folds:  72%[==================>      ]  ETA: 0:00:04\u001b[K\rEvaluating over 18 folds:  78%[===================>     ]  ETA: 0:00:03\u001b[K\rEvaluating over 18 folds:  83%[====================>    ]  ETA: 0:00:02\u001b[K\rEvaluating over 18 folds:  89%[======================>  ]  ETA: 0:00:01\u001b[K\rEvaluating over 18 folds:  94%[=======================> ]  ETA: 0:00:01\u001b[K\rEvaluating over 18 folds: 100%[=========================] Time: 0:00:13\u001b[K\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "┌\u001b[0m──────────────────────────────\u001b[0m┬\u001b[0m───────────────\u001b[0m┬\u001b[0m─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m┐\u001b[0m\n│\u001b[0m\u001b[22m _.measure                    \u001b[0m│\u001b[0m\u001b[22m _.measurement \u001b[0m│\u001b[0m\u001b[22m _.per_fold                                                                                                                                              \u001b[0m│\u001b[0m\n├\u001b[0m──────────────────────────────\u001b[0m┼\u001b[0m───────────────\u001b[0m┼\u001b[0m─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m┤\u001b[0m\n│\u001b[0m cross_entropy                \u001b[0m│\u001b[0m 0.306         \u001b[0m│\u001b[0m Float32[0.202, 0.259, 0.279, 0.387, 0.361, 0.384, 0.372, 0.283, 0.33, 0.323, 0.309, 0.24, 0.367, 0.252, 0.214, 0.266, 0.339, 0.339]                     \u001b[0m│\u001b[0m\n│\u001b[0m BrierScore{UnivariateFinite} \u001b[0m│\u001b[0m -0.161        \u001b[0m│\u001b[0m Float32[-0.11, -0.107, -0.141, -0.207, -0.208, -0.221, -0.209, -0.143, -0.178, -0.162, -0.165, -0.112, -0.203, -0.135, -0.0855, -0.126, -0.199, -0.195] \u001b[0m│\u001b[0m\n└\u001b[0m──────────────────────────────\u001b[0m┴\u001b[0m───────────────\u001b[0m┴\u001b[0m─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m┘\u001b[0m\n_.per_observation = [[[0.431, 0.019, ..., 0.0163], [0.319, 0.348, ..., 0.235], [0.38, 0.426, ..., 0.00927], [0.484, 0.558, ..., 0.333], [0.141, 0.18, ..., 0.18], [0.00216, 0.494, ..., 0.325], [0.322, 0.0095, ..., 0.323], [0.524, 0.585, ..., 0.0225], [0.412, 0.00947, ..., 0.622], [0.278, 0.173, ..., 0.139], [0.484, 0.00934, ..., 0.0126], [0.471, 0.00481, ..., 0.219], [0.619, 0.336, ..., 0.649], [0.348, 0.684, ..., 0.41], [0.162, 0.274, ..., 0.153], [0.31, 0.00402, ..., 0.428], [0.0294, 0.0278, ..., 0.025], [0.00174, 0.00137, ..., 0.435]], [[-0.212, -0.000711, ..., -0.000523], [-0.149, -0.168, ..., -0.0878], [-0.199, -0.24, ..., -0.00017], [-0.225, -0.306, ..., -0.16], [-0.0265, -0.0544, ..., -0.0544], [-9.3e-6, -0.278, ..., -0.117], [-0.152, -0.000179, ..., -0.152], [-0.253, -0.312, ..., -0.000987], [-0.171, -0.000178, ..., -0.375], [-0.105, -0.0505, ..., -0.0336], [-0.223, -0.000173, ..., -0.000314], [-0.278, -4.6e-5, ..., -0.0774], [-0.322, -0.162, ..., -0.342], [-0.157, -0.421, ..., -0.221], [-0.0449, -0.115, ..., -0.0356], [-0.139, -3.23e-5, ..., -0.232], [-0.00139, -0.00126, ..., -0.00102], [-6.08e-6, -3.81e-6, ..., -0.233]]]\n"
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "cell_type": "code",
   "source": [
    "e = evaluate!(mach, resampling=CV(nfolds=6, rng=123),\n",
    "                repeats=3,\n",
    "              measures=[cross_entropy, brier_score])"
   ],
   "metadata": {},
   "execution_count": 80
  },
  {
   "cell_type": "markdown",
   "source": [
    "One can access the following properties of the output `e` of an\n",
    "evaluation: `measure`, `measurement`, `per_fold` (measurement for\n",
    "each fold) and `per_observation` (measurement per observation, if\n",
    "reported)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We finally note that you can restrict the rows of observations from\n",
    "which train and test folds are drawn, by specifying `rows=...`. For\n",
    "example, imagining the last 30% of target observations are `missing`\n",
    "you might have a workflow like this:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Info: Creating subsamples from a subset of all rows. \n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/resampling.jl:336\n",
      "\rEvaluating over 6 folds:  17%[====>                    ]  ETA: 0:00:02\u001b[K\rEvaluating over 6 folds:  33%[========>                ]  ETA: 0:00:02\u001b[K\rEvaluating over 6 folds:  50%[============>            ]  ETA: 0:00:02\u001b[K\rEvaluating over 6 folds:  67%[================>        ]  ETA: 0:00:01\u001b[K\rEvaluating over 6 folds:  83%[====================>    ]  ETA: 0:00:01\u001b[K\rEvaluating over 6 folds: 100%[=========================] Time: 0:00:02\u001b[K\n",
      "┌ Info: Training \u001b[34mMachine{NeuralNetworkClassifier{Short,…}} @839\u001b[39m.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:317\n",
      "\rOptimising neural net:  2%[>                        ]  ETA: 0:00:00\u001b[K\rOptimising neural net:  4%[>                        ]  ETA: 0:00:00\u001b[K\rOptimising neural net:  6%[=>                       ]  ETA: 0:00:00\u001b[K\rOptimising neural net:  8%[=>                       ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 10%[==>                      ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 12%[==>                      ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 14%[===>                     ]  ETA: 0:00:01\u001b[K\rOptimising neural net: 16%[===>                     ]  ETA: 0:00:01\u001b[K\rOptimising neural net: 18%[====>                    ]  ETA: 0:00:01\u001b[K\rOptimising neural net: 20%[====>                    ]  ETA: 0:00:01\u001b[K\rOptimising neural net: 22%[=====>                   ]  ETA: 0:00:01\u001b[K\rOptimising neural net: 24%[=====>                   ]  ETA: 0:00:01\u001b[K\rOptimising neural net: 25%[======>                  ]  ETA: 0:00:01\u001b[K\rOptimising neural net: 27%[======>                  ]  ETA: 0:00:01\u001b[K\rOptimising neural net: 29%[=======>                 ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 31%[=======>                 ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 33%[========>                ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 35%[========>                ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 37%[=========>               ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 39%[=========>               ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 41%[==========>              ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 43%[==========>              ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 45%[===========>             ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 47%[===========>             ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 49%[============>            ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 51%[============>            ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 53%[=============>           ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 55%[=============>           ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 57%[==============>          ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 59%[==============>          ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 61%[===============>         ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 63%[===============>         ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 65%[================>        ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 67%[================>        ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 69%[=================>       ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 71%[=================>       ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 73%[==================>      ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 75%[==================>      ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 76%[===================>     ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 78%[===================>     ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 80%[====================>    ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 82%[====================>    ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 84%[=====================>   ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 86%[=====================>   ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 88%[======================>  ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 90%[======================>  ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 92%[=======================> ]  ETA: 0:00:00\u001b[K\rOptimising neural net: 96%[========================>]  ETA: 0:00:00\u001b[K\rOptimising neural net: 98%[========================>]  ETA: 0:00:00\u001b[K\rOptimising neural net:100%[=========================] Time: 0:00:00\u001b[K\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "train, test = partition(eachindex(y), 0.7)\n",
    "mach = machine(model, X, y)\n",
    "evaluate!(mach, resampling=CV(nfolds=6),\n",
    "          measures=[cross_entropy, brier_score],\n",
    "          rows=train)     # cv estimate, resampling from `train`\n",
    "fit!(mach, rows=train)    # re-train using all of `train` observations\n",
    "predict(mach, rows=test); # and predict missing targets"
   ],
   "metadata": {},
   "execution_count": 81
  },
  {
   "cell_type": "markdown",
   "source": [
    "### On learning curves"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since our model is an iterative one, we might want to inspect the\n",
    "out-of-sample performance as a function of the iteration\n",
    "parameter. For this we can use the `learning_curve` function (which,\n",
    "incidentally can be applied to any model hyper-parameter). This\n",
    "starts by defining a one-dimensional range object for the parameter\n",
    "(more on this when we discuss tuning in Part 4):"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{ProbabilisticTunedModel{Grid,…}} @244\u001b[39m.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:317\n",
      "┌ Info: Attempting to evaluate 22 models.\n",
      "└ @ MLJTuning /Users/anthony/.julia/packages/MLJTuning/oLVRR/src/tuned_models.jl:474\n",
      "\rEvaluating over 22 metamodels:   0%[>                        ]  ETA: N/A\u001b[K\rEvaluating over 22 metamodels:   5%[=>                       ]  ETA: 0:00:01\u001b[K\rEvaluating over 22 metamodels:   9%[==>                      ]  ETA: 0:00:01\u001b[K\rEvaluating over 22 metamodels:  14%[===>                     ]  ETA: 0:00:00\u001b[K\rEvaluating over 22 metamodels:  18%[====>                    ]  ETA: 0:00:00\u001b[K\rEvaluating over 22 metamodels:  23%[=====>                   ]  ETA: 0:00:00\u001b[K\rEvaluating over 22 metamodels:  27%[======>                  ]  ETA: 0:00:00\u001b[K\rEvaluating over 22 metamodels:  32%[=======>                 ]  ETA: 0:00:00\u001b[K\rEvaluating over 22 metamodels:  36%[=========>               ]  ETA: 0:00:00\u001b[K\rEvaluating over 22 metamodels:  41%[==========>              ]  ETA: 0:00:00\u001b[K\rEvaluating over 22 metamodels:  45%[===========>             ]  ETA: 0:00:00\u001b[K\rEvaluating over 22 metamodels:  50%[============>            ]  ETA: 0:00:00\u001b[K\rEvaluating over 22 metamodels:  55%[=============>           ]  ETA: 0:00:00\u001b[K\rEvaluating over 22 metamodels:  59%[==============>          ]  ETA: 0:00:00\u001b[K\rEvaluating over 22 metamodels:  64%[===============>         ]  ETA: 0:00:00\u001b[K\rEvaluating over 22 metamodels:  68%[=================>       ]  ETA: 0:00:00\u001b[K\rEvaluating over 22 metamodels:  73%[==================>      ]  ETA: 0:00:00\u001b[K\rEvaluating over 22 metamodels:  77%[===================>     ]  ETA: 0:00:00\u001b[K\rEvaluating over 22 metamodels:  82%[====================>    ]  ETA: 0:00:00\u001b[K\rEvaluating over 22 metamodels:  86%[=====================>   ]  ETA: 0:00:00\u001b[K\rEvaluating over 22 metamodels:  91%[======================>  ]  ETA: 0:00:00\u001b[K\rEvaluating over 22 metamodels:  95%[=======================> ]  ETA: 0:00:00\u001b[K\rEvaluating over 22 metamodels: 100%[=========================] Time: 0:00:00\u001b[K\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(parameter_name = \"epochs\",\n parameter_scale = :log,\n parameter_values = [1, 2, 3, 4, 5, 6, 7, 8, 10, 11  …  17, 19, 22, 26, 30, 34, 39, 45, 52, 60],\n measurements = [1.0338083505630493, 0.9733019471168518, 0.8096140623092651, 0.6991646885871887, 0.6084268093109131, 0.5542607307434082, 0.5336317420005798, 0.5063855648040771, 0.47317537665367126, 0.44297146797180176  …  0.3798142671585083, 0.39341121912002563, 0.29644110798835754, 0.3708436191082001, 0.3389438986778259, 0.2866306006908417, 0.2980813682079315, 0.2841547727584839, 0.28716742992401123, 0.2718779444694519],)"
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "cell_type": "code",
   "source": [
    "r = range(model, :epochs, lower=1, upper=60, scale=:log)\n",
    "curve = learning_curve(mach,\n",
    "                       range=r,\n",
    "                       resampling=Holdout(fraction_train=0.7), # (default)\n",
    "                       measure=cross_entropy)"
   ],
   "metadata": {},
   "execution_count": 82
  },
  {
   "cell_type": "markdown",
   "source": [
    "using Plots\n",
    "pyplot()\n",
    "plt=plot(curve.parameter_values, curve.measurements)\n",
    "xlabel!(plt, \"epochs\")\n",
    "ylabel!(plt, \"cross entropy on holdout set\")\n",
    "savefig(\"iris_learning_curve.png\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will return to learning curves when we look at tuning in Part 4."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Resources for Part 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- From the MLJ manual:\n",
    "    - [Getting Started](https://alan-turing-institute.github.io/MLJ.jl/dev/getting_started/)\n",
    "    - [Model Search](https://alan-turing-institute.github.io/MLJ.jl/dev/model_search/)\n",
    "    - [Evaluating Performance](https://alan-turing-institute.github.io/MLJ.jl/dev/evaluating_model_performance/) (using `evaluate!`)\n",
    "    - [Learning Curves](https://alan-turing-institute.github.io/MLJ.jl/dev/learning_curves/)\n",
    "    - [Performance Measures](https://alan-turing-institute.github.io/MLJ.jl/dev/performance_measures/) (loss functions, scores, etc)\n",
    "- From Data Science Tutorials:\n",
    "    - [Choosing and evaluating a model](https://alan-turing-institute.github.io/DataScienceTutorials.jl/getting-started/choosing-a-model/)\n",
    "    - [Fit, predict, transform](https://alan-turing-institute.github.io/DataScienceTutorials.jl/getting-started/fit-and-predict/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exercises for Part 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ex 4"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(a) Identify all supervised MLJ models that can be applied (without\n",
    "type coercion or one-hot encoding) to a supervised learning problem\n",
    "with input features `X4` and target `y4` defined below:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "10-element Array{Int64,1}:\n 1\n 0\n 0\n 2\n 0\n 0\n 1\n 4\n 3\n 0"
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "cell_type": "code",
   "source": [
    "import Distributions\n",
    "poisson = Distributions.Poisson\n",
    "\n",
    "age = 18 .+ 60*rand(10);\n",
    "salary = coerce(rand([:small, :big, :huge], 10), OrderedFactor);\n",
    "levels!(salary, [:small, :big, :huge]);\n",
    "X4 = DataFrames.DataFrame(age=age, salary=salary)\n",
    "\n",
    "n_devices(salary) = salary > :small ? rand(poisson(1.3)) : rand(poisson(2.9))\n",
    "y4 = [n_devices(row.salary) for row in eachrow(X4)]"
   ],
   "metadata": {},
   "execution_count": 83
  },
  {
   "cell_type": "markdown",
   "source": [
    "(b) What models can be applied if you coerce the salary to a\n",
    "`Continuous` scitype?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ex 5 (unpack)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "After evaluating the following ..."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────┬──────────────────────┬─────────────────────┬─────────────────────────────────┐\n",
      "│ a     │ b                    │ c                   │ d                               │\n",
      "│ Int64 │ Float64              │ Float64             │ CategoricalValue{String,UInt32} │\n",
      "│ Count │ Continuous           │ Continuous          │ OrderedFactor{2}                │\n",
      "├───────┼──────────────────────┼─────────────────────┼─────────────────────────────────┤\n",
      "│ 1     │ 0.6441721216226863   │ 0.6296110226768703  │ male                            │\n",
      "│ 2     │ 0.21229097362580585  │ 0.9030090781929387  │ female                          │\n",
      "│ 3     │ 0.012358733007368672 │ 0.10483128996037228 │ female                          │\n",
      "│ 4     │ 0.2648144644130588   │ 0.7981670696077316  │ male                            │\n",
      "└───────┴──────────────────────┴─────────────────────┴─────────────────────────────────┘\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "data = (a = [1, 2, 3, 4],\n",
    "     b = rand(4),\n",
    "     c = rand(4),\n",
    "     d = coerce([\"male\", \"female\", \"female\", \"male\"], OrderedFactor));\n",
    "pretty(data)\n",
    "\n",
    "using Tables\n",
    "y, X, w = unpack(data, ==(:a),\n",
    "                 name -> elscitype(Tables.getcolumn(data, name)) == Continuous,\n",
    "                 name -> true);"
   ],
   "metadata": {},
   "execution_count": 84
  },
  {
   "cell_type": "markdown",
   "source": [
    "...attempt to guess the evaluations of the following:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4-element Array{Int64,1}:\n 1\n 2\n 3\n 4"
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "cell_type": "code",
   "source": [
    "y"
   ],
   "metadata": {},
   "execution_count": 85
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────────────┬─────────────────────┐\n",
      "│ b                    │ c                   │\n",
      "│ Float64              │ Float64             │\n",
      "│ Continuous           │ Continuous          │\n",
      "├──────────────────────┼─────────────────────┤\n",
      "│ 0.6441721216226863   │ 0.6296110226768703  │\n",
      "│ 0.21229097362580585  │ 0.9030090781929387  │\n",
      "│ 0.012358733007368672 │ 0.10483128996037228 │\n",
      "│ 0.2648144644130588   │ 0.7981670696077316  │\n",
      "└──────────────────────┴─────────────────────┘\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "pretty(X)"
   ],
   "metadata": {},
   "execution_count": 86
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4-element CategoricalArray{String,1,UInt32}:\n \"male\"\n \"female\"\n \"female\"\n \"male\""
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "cell_type": "code",
   "source": [
    "w"
   ],
   "metadata": {},
   "execution_count": 87
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ex 6 (first steps in modelling Horse Colic)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(a) Suppose we want to use predict the `:outcome` variable in the\n",
    "Horse Colic study introduced in Part 1, based on the remaining\n",
    "variables that are `Continuous` (one-hot encoding categorical\n",
    "variables is discussed later in Part 3) *while ignoring the others*.\n",
    "Extract from the `horse` data set (defined in Part 1) appropriate\n",
    "input features `X` and target variable `y`. (Do not, however,\n",
    "randomize the observations.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(b) Create a 70:30 `train`/`test` split of the data and train a\n",
    "`LogisticClassifier` model, from the `MLJLinearModels` package, on\n",
    "the `train` rows. Use `lambda=100` and default values for the\n",
    "other hyper-parameters. (Although one would normally standardize\n",
    "(whiten) the continuous features for this model, do not do so here.)\n",
    "After training:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- (i) Recalling that a logistic classifier (aka logistic regressor) is\n",
    "  a linear-based model learning a *vector* of coefficients for each\n",
    "  feature (one coefficient for each target class), use the\n",
    "  `fitted_params` method to find this vector of coefficients in the\n",
    "  case of the `:pulse` feature. (To convert a vector of pairs `v =\n",
    "  [x1 => y1, x2 => y2, ...]` into a dictionary, do `Dict(v)`.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- (ii) Evaluate the `cross_entropy` performance on the `test`\n",
    "  observations."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- &star;(iii) In how many `test` observations does the predicted\n",
    "  probablility of the observed class exceed 50%?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- (iv) Find the `misclassification_rate` in the `test`\n",
    "  set. (*Hint.* As this measure is deterministic, you will either\n",
    "  need to broadcast `mode` or use `predict_mode` instead of\n",
    "  `predict`.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(c) Instead use a `RandomForestClassifier` model from the\n",
    "    `DecisionTree` package and:\n",
    "\n",
    "- (i) Generate an appropriate learning curve to convince yourself\n",
    "  that out-of-sample estimates of the `cross_entropy` loss do not\n",
    "  substatially improve for `n_trees > 50`. Use default values for\n",
    "  all other hyper-parameters, and feel free to use all available\n",
    "  data to generate the curve."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- (ii) Fix `n_trees=90` and use `evaluate!` to obtain a 9-fold\n",
    "  cross-validation estimate of the `cross_entropy`, restricting\n",
    "  sub-sampling to the `train` observations."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- (iii) Now use *all* available data but set\n",
    "  `resampling=Holdout(fraction_train=0.7)` to obtain a score you can\n",
    "  compare with the `KNNClassifier` in part (b)(iii). Which model is\n",
    "  better?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 3 - Transformers and Pipelines"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Transformers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unsupervised models, which receive no target `y` during training,\n",
    "always have a `transform` operation. They sometimes also support an\n",
    "`inverse_transform` operation, with obvious meaning, and sometimes\n",
    "support a `predict` operation operation (eg, some clustering\n",
    "algorithms). Otherwise, they are handled much like supervised\n",
    "models."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For an illustration, let's re-encode *all* of the King County House\n",
    "input features (see [Ex 3](#ex-3-fixing-scitypes-in-a-table)) into a\n",
    "set of `Continuous` features. We do this with the `ContinousEncoder`\n",
    "model, which, by default, will:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- one-hot encode all `Multiclass` features\n",
    "- coerce all `OrderedFactor` features to `Continuous` ones\n",
    "- coerce all `Count` features to `Continuous` ones (there aren't any)\n",
    "- drop any remaining non-Continuous features (there won't be any of these)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, we load a version of the data with scitypes already fixed:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "┌\u001b[0m───────────────\u001b[0m┬\u001b[0m──────────────────────────────────\u001b[0m┬\u001b[0m───────────────────\u001b[0m┐\u001b[0m\n│\u001b[0m\u001b[22m _.names       \u001b[0m│\u001b[0m\u001b[22m _.types                          \u001b[0m│\u001b[0m\u001b[22m _.scitypes        \u001b[0m│\u001b[0m\n├\u001b[0m───────────────\u001b[0m┼\u001b[0m──────────────────────────────────\u001b[0m┼\u001b[0m───────────────────\u001b[0m┤\u001b[0m\n│\u001b[0m price         \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m bedrooms      \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32}   \u001b[0m│\u001b[0m OrderedFactor{13} \u001b[0m│\u001b[0m\n│\u001b[0m bathrooms     \u001b[0m│\u001b[0m CategoricalValue{Float64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{30} \u001b[0m│\u001b[0m\n│\u001b[0m sqft_living   \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m sqft_lot      \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m floors        \u001b[0m│\u001b[0m CategoricalValue{Float64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{6}  \u001b[0m│\u001b[0m\n│\u001b[0m waterfront    \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32}   \u001b[0m│\u001b[0m OrderedFactor{2}  \u001b[0m│\u001b[0m\n│\u001b[0m view          \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32}   \u001b[0m│\u001b[0m OrderedFactor{5}  \u001b[0m│\u001b[0m\n│\u001b[0m condition     \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32}   \u001b[0m│\u001b[0m OrderedFactor{5}  \u001b[0m│\u001b[0m\n│\u001b[0m grade         \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32}   \u001b[0m│\u001b[0m OrderedFactor{12} \u001b[0m│\u001b[0m\n│\u001b[0m sqft_above    \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m sqft_basement \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m yr_built      \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m zipcode       \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32}   \u001b[0m│\u001b[0m Multiclass{70}    \u001b[0m│\u001b[0m\n│\u001b[0m lat           \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m long          \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m sqft_living15 \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m sqft_lot15    \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m is_renovated  \u001b[0m│\u001b[0m CategoricalValue{Bool,UInt32}    \u001b[0m│\u001b[0m OrderedFactor{2}  \u001b[0m│\u001b[0m\n└\u001b[0m───────────────\u001b[0m┴\u001b[0m──────────────────────────────────\u001b[0m┴\u001b[0m───────────────────\u001b[0m┘\u001b[0m\n_.nrows = 21613\n"
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "cell_type": "code",
   "source": [
    "file = CSV.File(joinpath(DIR, \"data\", \"house.csv\"));\n",
    "house = DataFrames.DataFrame(file)\n",
    "coerce!(house, autotype(file))\n",
    "coerce!(house, Count => Continuous, :zipcode => Multiclass);\n",
    "schema(house)"
   ],
   "metadata": {},
   "execution_count": 88
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "y, X = unpack(house, ==(:price), name -> true, rng=123);"
   ],
   "metadata": {},
   "execution_count": 89
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instantiate the unsupervised model (transformer):"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "ContinuousEncoder(\n    drop_last = false,\n    one_hot_ordered_factors = false)\u001b[34m @347\u001b[39m"
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "cell_type": "code",
   "source": [
    "encoder = ContinuousEncoder() # a built-in model; no need to @load it"
   ],
   "metadata": {},
   "execution_count": 90
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bind the model to the data and fit!"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{ContinuousEncoder} @616\u001b[39m.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:317\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "mach = machine(encoder, X) |> fit!;"
   ],
   "metadata": {},
   "execution_count": 91
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transform and inspect the result:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "┌\u001b[0m────────────────\u001b[0m┬\u001b[0m─────────\u001b[0m┬\u001b[0m────────────\u001b[0m┐\u001b[0m\n│\u001b[0m\u001b[22m _.names        \u001b[0m│\u001b[0m\u001b[22m _.types \u001b[0m│\u001b[0m\u001b[22m _.scitypes \u001b[0m│\u001b[0m\n├\u001b[0m────────────────\u001b[0m┼\u001b[0m─────────\u001b[0m┼\u001b[0m────────────\u001b[0m┤\u001b[0m\n│\u001b[0m bedrooms       \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m bathrooms      \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m sqft_living    \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m sqft_lot       \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m floors         \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m waterfront     \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m view           \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m condition      \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m grade          \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m sqft_above     \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m sqft_basement  \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m yr_built       \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98001 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98002 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98003 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98004 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98005 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98006 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98007 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98008 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98010 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98011 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98014 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98019 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98022 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98023 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98024 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98027 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98028 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98029 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98030 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98031 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98032 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98033 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98034 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98038 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98039 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98040 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98042 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98045 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98052 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98053 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98055 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98056 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98058 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98059 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98065 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98070 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98072 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98074 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98075 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98077 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98092 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98102 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98103 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98105 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98106 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98107 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98108 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98109 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98112 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98115 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98116 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98117 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98118 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98119 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98122 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98125 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98126 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98133 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98136 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98144 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98146 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98148 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98155 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98166 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98168 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98177 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98178 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98188 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98198 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m zipcode__98199 \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m lat            \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m long           \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m sqft_living15  \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m sqft_lot15     \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m is_renovated   \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n└\u001b[0m────────────────\u001b[0m┴\u001b[0m─────────\u001b[0m┴\u001b[0m────────────\u001b[0m┘\u001b[0m\n_.nrows = 21613\n"
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "cell_type": "code",
   "source": [
    "Xcont = transform(mach, X);\n",
    "schema(Xcont)"
   ],
   "metadata": {},
   "execution_count": 92
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here's a list of MLJ's built-in transformers:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "28-element Array{NamedTuple{(:name, :package_name, :is_supervised, :docstring, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :is_pure_julia, :is_wrapper, :load_path, :package_license, :package_url, :package_uuid, :prediction_type, :supports_online, :supports_weights, :input_scitype, :target_scitype, :output_scitype),T} where T<:Tuple,1}:\n (name = AffinityPropagation, package_name = ScikitLearn, ... )\n (name = AgglomerativeClustering, package_name = ScikitLearn, ... )\n (name = Birch, package_name = ScikitLearn, ... )\n (name = ContinuousEncoder, package_name = MLJModels, ... )\n (name = DBSCAN, package_name = ScikitLearn, ... )\n (name = FeatureAgglomeration, package_name = ScikitLearn, ... )\n (name = FeatureSelector, package_name = MLJModels, ... )\n (name = FillImputer, package_name = MLJModels, ... )\n (name = ICA, package_name = MultivariateStats, ... )\n (name = KMeans, package_name = Clustering, ... )\n (name = KMeans, package_name = ParallelKMeans, ... )\n (name = KMeans, package_name = ScikitLearn, ... )\n (name = KMedoids, package_name = Clustering, ... )\n (name = KernelPCA, package_name = MultivariateStats, ... )\n (name = MeanShift, package_name = ScikitLearn, ... )\n (name = MiniBatchKMeans, package_name = ScikitLearn, ... )\n (name = OPTICS, package_name = ScikitLearn, ... )\n (name = OneClassSVM, package_name = LIBSVM, ... )\n (name = OneHotEncoder, package_name = MLJModels, ... )\n (name = PCA, package_name = MultivariateStats, ... )\n (name = SpectralClustering, package_name = ScikitLearn, ... )\n (name = Standardizer, package_name = MLJModels, ... )\n (name = StaticSurrogate, package_name = MLJBase, ... )\n (name = UnivariateBoxCoxTransformer, package_name = MLJModels, ... )\n (name = UnivariateDiscretizer, package_name = MLJModels, ... )\n (name = UnivariateStandardizer, package_name = MLJModels, ... )\n (name = UnsupervisedSurrogate, package_name = MLJBase, ... )\n (name = WrappedFunction, package_name = MLJBase, ... )"
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "cell_type": "code",
   "source": [
    "models(m->!m.is_supervised)"
   ],
   "metadata": {},
   "execution_count": 93
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some commonly used ones are built-in (do not require `@load`ing):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "model type                  | does what?\n",
    "----------------------------|----------------------------------------------\n",
    "ContinuousEncoder | transform input to a table of `Continuous` features (see above)\n",
    "FeatureSelector | retain or dump selected features\n",
    "FillImputer | impute missing values\n",
    "OneHotEncoder | one-hot encoder `Multiclass` (and optionally `OrderedFactor`) features\n",
    "Standardizer | standardize (whiten) the `Continuous` features in a table\n",
    "UnivariateBoxCoxTransformer | apply a learned Box-Cox transformation to a vector\n",
    "UnivariateDiscretizer | discretize a `Continuous` vector, and hence render its elscityp `OrderedFactor`\n",
    "UnivariateStandardizer| standardize (whiten) a `Continuous` vector"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pipelines"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "87"
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "cell_type": "code",
   "source": [
    "length(schema(Xcont).names)"
   ],
   "metadata": {},
   "execution_count": 94
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's suppose that additionally we'd like to reduce the dimension of\n",
    "our data.  A model that will do this is `PCA` from\n",
    "`MultivariateStats`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "PCA(\n    maxoutdim = nothing,\n    method = :auto,\n    pratio = 0.99,\n    mean = nothing)\u001b[34m @424\u001b[39m"
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "cell_type": "code",
   "source": [
    "reducer = @load PCA"
   ],
   "metadata": {},
   "execution_count": 95
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, rather simply repeating the workflow above, applying the new\n",
    "transformation to `Xcont`, we can combine both the encoding and the\n",
    "dimension-reducing models into a single model, known as a\n",
    "*pipeline*. While MLJ offers a powerful interface for composing\n",
    "models in a variety of ways, we'll stick to these simplest class of\n",
    "composite models for now. The easiest way to construct them is using\n",
    "the `@pipeline` macro:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline772(\n    continuous_encoder = ContinuousEncoder(\n            drop_last = false,\n            one_hot_ordered_factors = false),\n    pca = PCA(\n            maxoutdim = nothing,\n            method = :auto,\n            pratio = 0.99,\n            mean = nothing))\u001b[34m @533\u001b[39m"
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "cell_type": "code",
   "source": [
    "pipe = @pipeline encoder reducer"
   ],
   "metadata": {},
   "execution_count": 96
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice that `pipe` is an *instance* of an automatically generated\n",
    "type called `Pipeline???`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The new model behaves like any other transformer:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{Pipeline772} @731\u001b[39m.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:317\n",
      "┌ Info: Training \u001b[34mMachine{ContinuousEncoder} @525\u001b[39m.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:317\n",
      "┌ Info: Training \u001b[34mMachine{PCA} @851\u001b[39m.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:317\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "┌\u001b[0m─────────\u001b[0m┬\u001b[0m─────────\u001b[0m┬\u001b[0m────────────\u001b[0m┐\u001b[0m\n│\u001b[0m\u001b[22m _.names \u001b[0m│\u001b[0m\u001b[22m _.types \u001b[0m│\u001b[0m\u001b[22m _.scitypes \u001b[0m│\u001b[0m\n├\u001b[0m─────────\u001b[0m┼\u001b[0m─────────\u001b[0m┼\u001b[0m────────────\u001b[0m┤\u001b[0m\n│\u001b[0m x1      \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n│\u001b[0m x2      \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n└\u001b[0m─────────\u001b[0m┴\u001b[0m─────────\u001b[0m┴\u001b[0m────────────\u001b[0m┘\u001b[0m\n_.nrows = 21613\n"
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "cell_type": "code",
   "source": [
    "mach = machine(pipe, X) |> fit!;\n",
    "Xsmall = transform(mach, X)\n",
    "schema(Xsmall)"
   ],
   "metadata": {},
   "execution_count": 97
  },
  {
   "cell_type": "markdown",
   "source": [
    "Want to combine this pre-processing with a logistic classifier?"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline780(\n    continuous_encoder = ContinuousEncoder(\n            drop_last = false,\n            one_hot_ordered_factors = false),\n    pca = PCA(\n            maxoutdim = nothing,\n            method = :auto,\n            pratio = 0.99,\n            mean = nothing),\n    ridge_regressor = RidgeRegressor(\n            lambda = 1.0,\n            fit_intercept = true,\n            penalize_intercept = false,\n            solver = nothing))\u001b[34m @438\u001b[39m"
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "cell_type": "code",
   "source": [
    "rgs = @load RidgeRegressor pkg=MLJLinearModels\n",
    "pipe2 = @pipeline encoder reducer rgs"
   ],
   "metadata": {},
   "execution_count": 98
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now our pipeline is a supervised model, instead of a transformer:\n",
    "whose performance we can evaluate:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{Pipeline780} @223\u001b[39m.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:317\n",
      "┌ Info: Training \u001b[34mMachine{ContinuousEncoder} @238\u001b[39m.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:317\n",
      "┌ Info: Training \u001b[34mMachine{PCA} @092\u001b[39m.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:317\n",
      "┌ Info: Training \u001b[34mMachine{RidgeRegressor} @013\u001b[39m.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:317\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "┌\u001b[0m───────────\u001b[0m┬\u001b[0m───────────────\u001b[0m┬\u001b[0m────────────\u001b[0m┐\u001b[0m\n│\u001b[0m\u001b[22m _.measure \u001b[0m│\u001b[0m\u001b[22m _.measurement \u001b[0m│\u001b[0m\u001b[22m _.per_fold \u001b[0m│\u001b[0m\n├\u001b[0m───────────\u001b[0m┼\u001b[0m───────────────\u001b[0m┼\u001b[0m────────────\u001b[0m┤\u001b[0m\n│\u001b[0m mae       \u001b[0m│\u001b[0m 234000.0      \u001b[0m│\u001b[0m [234000.0] \u001b[0m│\u001b[0m\n└\u001b[0m───────────\u001b[0m┴\u001b[0m───────────────\u001b[0m┴\u001b[0m────────────\u001b[0m┘\u001b[0m\n_.per_observation = [missing]\n"
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "cell_type": "code",
   "source": [
    "mach = machine(pipe2, X, y) |> fit!\n",
    "evaluate!(mach, measure=mae, resampling=Holdout()) # CV(nfolds=6) is default"
   ],
   "metadata": {},
   "execution_count": 99
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training of composite models is \"smart\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now notice what happens if we train on all the data, then change a\n",
    "regressor hyper-parameter and retrain:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{Pipeline780} @223\u001b[39m.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:317\n",
      "┌ Info: Training \u001b[34mMachine{ContinuousEncoder} @666\u001b[39m.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:317\n",
      "┌ Info: Training \u001b[34mMachine{PCA} @559\u001b[39m.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:317\n",
      "┌ Info: Training \u001b[34mMachine{RidgeRegressor} @544\u001b[39m.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:317\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34mMachine{Pipeline780} @223\u001b[39m trained 3 times.\n  args: \n    1:\t\u001b[34mSource @020\u001b[39m ⏎ `Table{Union{AbstractArray{Continuous,1}, AbstractArray{Multiclass{70},1}, AbstractArray{OrderedFactor{6},1}, AbstractArray{OrderedFactor{13},1}, AbstractArray{OrderedFactor{30},1}, AbstractArray{OrderedFactor{5},1}, AbstractArray{OrderedFactor{12},1}, AbstractArray{OrderedFactor{2},1}}}`\n    2:\t\u001b[34mSource @121\u001b[39m ⏎ `AbstractArray{Continuous,1}`\n"
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "cell_type": "code",
   "source": [
    "fit!(mach)"
   ],
   "metadata": {},
   "execution_count": 100
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Info: Updating \u001b[34mMachine{Pipeline780} @223\u001b[39m.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:318\n",
      "┌ Info: Not retraining \u001b[34mMachine{ContinuousEncoder} @666\u001b[39m. Use `force=true` to force.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:320\n",
      "┌ Info: Not retraining \u001b[34mMachine{PCA} @559\u001b[39m. Use `force=true` to force.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:320\n",
      "┌ Info: Updating \u001b[34mMachine{RidgeRegressor} @544\u001b[39m.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:318\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34mMachine{Pipeline780} @223\u001b[39m trained 4 times.\n  args: \n    1:\t\u001b[34mSource @020\u001b[39m ⏎ `Table{Union{AbstractArray{Continuous,1}, AbstractArray{Multiclass{70},1}, AbstractArray{OrderedFactor{6},1}, AbstractArray{OrderedFactor{13},1}, AbstractArray{OrderedFactor{30},1}, AbstractArray{OrderedFactor{5},1}, AbstractArray{OrderedFactor{12},1}, AbstractArray{OrderedFactor{2},1}}}`\n    2:\t\u001b[34mSource @121\u001b[39m ⏎ `AbstractArray{Continuous,1}`\n"
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "cell_type": "code",
   "source": [
    "pipe2.ridge_regressor.lambda = 0.1\n",
    "fit!(mach)"
   ],
   "metadata": {},
   "execution_count": 101
  },
  {
   "cell_type": "markdown",
   "source": [
    "Second time only the ridge regressor is retrained!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mutate a hyper-parameter of the `PCA` model and every model except\n",
    "the `ContinuousEncoder` (which comes before it will be retrained):"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Info: Updating \u001b[34mMachine{Pipeline780} @223\u001b[39m.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:318\n",
      "┌ Info: Not retraining \u001b[34mMachine{ContinuousEncoder} @666\u001b[39m. Use `force=true` to force.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:320\n",
      "┌ Info: Updating \u001b[34mMachine{PCA} @559\u001b[39m.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:318\n",
      "┌ Info: Training \u001b[34mMachine{RidgeRegressor} @544\u001b[39m.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:317\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34mMachine{Pipeline780} @223\u001b[39m trained 5 times.\n  args: \n    1:\t\u001b[34mSource @020\u001b[39m ⏎ `Table{Union{AbstractArray{Continuous,1}, AbstractArray{Multiclass{70},1}, AbstractArray{OrderedFactor{6},1}, AbstractArray{OrderedFactor{13},1}, AbstractArray{OrderedFactor{30},1}, AbstractArray{OrderedFactor{5},1}, AbstractArray{OrderedFactor{12},1}, AbstractArray{OrderedFactor{2},1}}}`\n    2:\t\u001b[34mSource @121\u001b[39m ⏎ `AbstractArray{Continuous,1}`\n"
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "cell_type": "code",
   "source": [
    "pipe2.pca.pratio = 0.9999\n",
    "fit!(mach)"
   ],
   "metadata": {},
   "execution_count": 102
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inspecting composite models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dot syntax used above to change the values of *nested*\n",
    "hyper-parameters is also useful when inspecting the learned\n",
    "parameters and report generated when training a composite model:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(coefs = [:x1 => -0.7328956348956883, :x2 => -0.16590563202915296, :x3 => 194.59515890822158, :x4 => 102.7130175613619],\n intercept = 540085.6428739978,)"
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "cell_type": "code",
   "source": [
    "fitted_params(mach).ridge_regressor"
   ],
   "metadata": {},
   "execution_count": 103
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(indim = 87,\n outdim = 4,\n mean = [4.369869985656781, 8.459121824827651, 2079.899736269838, 15106.96756581687, 1.988617961412113, 1.0075417572757137, 1.2343034284921113, 3.4094295100171195, 6.6569194466293435, 1788.3906907879518  …  0.011798454633785222, 0.012122333780595013, 0.006292509138018786, 0.012955165872391617, 0.01466709850552908, 47.56005251931713, -122.21389640494186, 1986.5524915560081, 12768.455651691113, 1.9577106371165505],\n principalvars = [2.177071551045085e9, 2.841813972643024e8, 1.6850160830643424e6, 277281.83841321553],\n tprincipalvar = 2.463215246230865e9,\n tresidualvar = 157533.26199674606,\n tvar = 2.4633727794928617e9,)"
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "cell_type": "code",
   "source": [
    "report(mach).pca"
   ],
   "metadata": {},
   "execution_count": 104
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Incorporating target transformations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, suppose that instead of using the raw `:price` as the\n",
    "training target, we want to use the log-price (a common practice in\n",
    "dealing with house price data). However, suppose that we still want\n",
    "to report final *predictions* on the original linear scale (and use\n",
    "these for evaluation purposes). Then we supply appropriate functions\n",
    "to key-word arguments `target` and `inverse`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we'll overload `log` and `exp` for broadcasting:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Base.log(v::AbstractArray) = log.(v)\n",
    "Base.exp(v::AbstractArray) = exp.(v)"
   ],
   "metadata": {},
   "execution_count": 105
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now for the new pipeline:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Info: Treating pipeline as a `Deterministic` predictor.\n",
      "│ To override, specify `prediction_type=...` (options: :deterministic, :probabilistic, :interval). \n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/composition/models/pipelines.jl:394\n",
      "\rEvaluating over 6 folds:  17%[====>                    ]  ETA: 0:00:02\u001b[K\rEvaluating over 6 folds:  33%[========>                ]  ETA: 0:00:01\u001b[K\rEvaluating over 6 folds:  50%[============>            ]  ETA: 0:00:01\u001b[K\rEvaluating over 6 folds:  67%[================>        ]  ETA: 0:00:00\u001b[K\rEvaluating over 6 folds:  83%[====================>    ]  ETA: 0:00:00\u001b[K\rEvaluating over 6 folds: 100%[=========================] Time: 0:00:01\u001b[K\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "┌\u001b[0m───────────\u001b[0m┬\u001b[0m───────────────\u001b[0m┬\u001b[0m──────────────────────────────────────────────────────────────\u001b[0m┐\u001b[0m\n│\u001b[0m\u001b[22m _.measure \u001b[0m│\u001b[0m\u001b[22m _.measurement \u001b[0m│\u001b[0m\u001b[22m _.per_fold                                                   \u001b[0m│\u001b[0m\n├\u001b[0m───────────\u001b[0m┼\u001b[0m───────────────\u001b[0m┼\u001b[0m──────────────────────────────────────────────────────────────\u001b[0m┤\u001b[0m\n│\u001b[0m mae       \u001b[0m│\u001b[0m 162000.0      \u001b[0m│\u001b[0m [160000.0, 161000.0, 164000.0, 159000.0, 173000.0, 157000.0] \u001b[0m│\u001b[0m\n└\u001b[0m───────────\u001b[0m┴\u001b[0m───────────────\u001b[0m┴\u001b[0m──────────────────────────────────────────────────────────────\u001b[0m┘\u001b[0m\n_.per_observation = [missing]\n"
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "cell_type": "code",
   "source": [
    "pipe3 = @pipeline encoder reducer rgs target=log inverse=exp\n",
    "mach = machine(pipe3, X, y)\n",
    "evaluate!(mach, measure=mae)"
   ],
   "metadata": {},
   "execution_count": 106
  },
  {
   "cell_type": "markdown",
   "source": [
    "MLJ will even allow you to insert *learned* target\n",
    "transformations. For example, we might want to apply\n",
    "`UnivariateStandardizer()` to the target, to standarize it, or\n",
    "`UnivariateBoxCoxTransformer()` to make it look Gaussian. Then\n",
    "instead of specifying a *function* for `target`, we specify a model\n",
    "(or model type). One does not specify `inverse` because these are\n",
    "models that implement `inverse_transform` in addition to\n",
    "`transform`:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 4 - Tuning hyper-parameters"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "MLJBase.NumericRange(Float64, :(ridge_regressor.lambda), ... )"
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "cell_type": "code",
   "source": [
    "r = range(pipe3, :(ridge_regressor.lambda), lower = 1e-6, upper=10, scale=:log)"
   ],
   "metadata": {},
   "execution_count": 107
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you're curious, you can see what `lambda` values this range will\n",
    "generate for a given resolution:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "10-element Array{Float64,1}:\n  1.0000000000000004e-6\n  5.994842503189412e-6\n  3.593813663804628e-5\n  0.0002154434690031884\n  0.0012915496650148838\n  0.007742636826811276\n  0.046415888336127795\n  0.27825594022071254\n  1.668100537200059\n 10.000000000000002"
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "cell_type": "code",
   "source": [
    "iterator(r, 10)"
   ],
   "metadata": {},
   "execution_count": 108
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Solutions to exercises"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ex 2 solution"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Info: Trying to coerce from `Union{Missing, String}` to `OrderedFactor`.\n",
      "│ Coerced to `Union{Missing,OrderedFactor}` instead.\n",
      "└ @ MLJScientificTypes /Users/anthony/.julia/packages/MLJScientificTypes/wqfgN/src/convention/coerce.jl:126\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Union{Missing, OrderedFactor{3}}"
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "cell_type": "code",
   "source": [
    "quality = coerce(quality, OrderedFactor);\n",
    "levels!(quality, [\"poor\", \"good\", \"excellent\"]);\n",
    "elscitype(quality)"
   ],
   "metadata": {},
   "execution_count": 109
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ex 3 solution"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First pass:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "┌\u001b[0m───────────────\u001b[0m┬\u001b[0m──────────────────────────────────\u001b[0m┬\u001b[0m───────────────────\u001b[0m┐\u001b[0m\n│\u001b[0m\u001b[22m _.names       \u001b[0m│\u001b[0m\u001b[22m _.types                          \u001b[0m│\u001b[0m\u001b[22m _.scitypes        \u001b[0m│\u001b[0m\n├\u001b[0m───────────────\u001b[0m┼\u001b[0m──────────────────────────────────\u001b[0m┼\u001b[0m───────────────────\u001b[0m┤\u001b[0m\n│\u001b[0m price         \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m bedrooms      \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32}   \u001b[0m│\u001b[0m OrderedFactor{13} \u001b[0m│\u001b[0m\n│\u001b[0m bathrooms     \u001b[0m│\u001b[0m CategoricalValue{Float64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{30} \u001b[0m│\u001b[0m\n│\u001b[0m sqft_living   \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m sqft_lot      \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m floors        \u001b[0m│\u001b[0m CategoricalValue{Float64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{6}  \u001b[0m│\u001b[0m\n│\u001b[0m waterfront    \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32}   \u001b[0m│\u001b[0m OrderedFactor{2}  \u001b[0m│\u001b[0m\n│\u001b[0m view          \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32}   \u001b[0m│\u001b[0m OrderedFactor{5}  \u001b[0m│\u001b[0m\n│\u001b[0m condition     \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32}   \u001b[0m│\u001b[0m OrderedFactor{5}  \u001b[0m│\u001b[0m\n│\u001b[0m grade         \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32}   \u001b[0m│\u001b[0m OrderedFactor{12} \u001b[0m│\u001b[0m\n│\u001b[0m sqft_above    \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m sqft_basement \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m yr_built      \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m zipcode       \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32}   \u001b[0m│\u001b[0m Multiclass{70}    \u001b[0m│\u001b[0m\n│\u001b[0m lat           \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m long          \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m sqft_living15 \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m sqft_lot15    \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m is_renovated  \u001b[0m│\u001b[0m CategoricalValue{Bool,UInt32}    \u001b[0m│\u001b[0m OrderedFactor{2}  \u001b[0m│\u001b[0m\n└\u001b[0m───────────────\u001b[0m┴\u001b[0m──────────────────────────────────\u001b[0m┴\u001b[0m───────────────────\u001b[0m┘\u001b[0m\n_.nrows = 21613\n"
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "cell_type": "code",
   "source": [
    "coerce!(house, autotype(house));\n",
    "schema(house)"
   ],
   "metadata": {},
   "execution_count": 110
  },
  {
   "cell_type": "markdown",
   "source": [
    "All the \"sqft\" fields refer to \"square feet\" so are\n",
    "really `Continuous`. We'll regard `:yr_built` (the other `Count`\n",
    "variable above) as `Continuous` as well. So:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "coerce!(house, Count => Continuous);"
   ],
   "metadata": {},
   "execution_count": 111
  },
  {
   "cell_type": "markdown",
   "source": [
    "And `:zipcode` should not be ordered:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "┌\u001b[0m───────────────\u001b[0m┬\u001b[0m──────────────────────────────────\u001b[0m┬\u001b[0m───────────────────\u001b[0m┐\u001b[0m\n│\u001b[0m\u001b[22m _.names       \u001b[0m│\u001b[0m\u001b[22m _.types                          \u001b[0m│\u001b[0m\u001b[22m _.scitypes        \u001b[0m│\u001b[0m\n├\u001b[0m───────────────\u001b[0m┼\u001b[0m──────────────────────────────────\u001b[0m┼\u001b[0m───────────────────\u001b[0m┤\u001b[0m\n│\u001b[0m price         \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m bedrooms      \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32}   \u001b[0m│\u001b[0m OrderedFactor{13} \u001b[0m│\u001b[0m\n│\u001b[0m bathrooms     \u001b[0m│\u001b[0m CategoricalValue{Float64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{30} \u001b[0m│\u001b[0m\n│\u001b[0m sqft_living   \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m sqft_lot      \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m floors        \u001b[0m│\u001b[0m CategoricalValue{Float64,UInt32} \u001b[0m│\u001b[0m OrderedFactor{6}  \u001b[0m│\u001b[0m\n│\u001b[0m waterfront    \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32}   \u001b[0m│\u001b[0m OrderedFactor{2}  \u001b[0m│\u001b[0m\n│\u001b[0m view          \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32}   \u001b[0m│\u001b[0m OrderedFactor{5}  \u001b[0m│\u001b[0m\n│\u001b[0m condition     \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32}   \u001b[0m│\u001b[0m OrderedFactor{5}  \u001b[0m│\u001b[0m\n│\u001b[0m grade         \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32}   \u001b[0m│\u001b[0m OrderedFactor{12} \u001b[0m│\u001b[0m\n│\u001b[0m sqft_above    \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m sqft_basement \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m yr_built      \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m zipcode       \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32}   \u001b[0m│\u001b[0m Multiclass{70}    \u001b[0m│\u001b[0m\n│\u001b[0m lat           \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m long          \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m sqft_living15 \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m sqft_lot15    \u001b[0m│\u001b[0m Float64                          \u001b[0m│\u001b[0m Continuous        \u001b[0m│\u001b[0m\n│\u001b[0m is_renovated  \u001b[0m│\u001b[0m CategoricalValue{Bool,UInt32}    \u001b[0m│\u001b[0m OrderedFactor{2}  \u001b[0m│\u001b[0m\n└\u001b[0m───────────────\u001b[0m┴\u001b[0m──────────────────────────────────\u001b[0m┴\u001b[0m───────────────────\u001b[0m┘\u001b[0m\n_.nrows = 21613\n"
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "cell_type": "code",
   "source": [
    "coerce!(house, :zipcode => Multiclass);\n",
    "schema(house)"
   ],
   "metadata": {},
   "execution_count": 112
  },
  {
   "cell_type": "markdown",
   "source": [
    "`:bathrooms` looks like it has a lot of levels, but on further\n",
    "inspection we see why, and `OrderedFactor` remains appropriate:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Dict{CategoricalValue{Float64,UInt32},Int64} with 30 entries:\n  CategoricalValue{Float64,UInt32} 5.5 (22/30)  => 10\n  CategoricalValue{Float64,UInt32} 6.5 (26/30)  => 2\n  CategoricalValue{Float64,UInt32} 2.0 (8/30)   => 1930\n  CategoricalValue{Float64,UInt32} 1.5 (6/30)   => 1446\n  CategoricalValue{Float64,UInt32} 3.25 (13/30) => 589\n  CategoricalValue{Float64,UInt32} 4.75 (19/30) => 23\n  CategoricalValue{Float64,UInt32} 4.5 (18/30)  => 100\n  CategoricalValue{Float64,UInt32} 6.75 (27/30) => 2\n  CategoricalValue{Float64,UInt32} 0.0 (1/30)   => 10\n  CategoricalValue{Float64,UInt32} 2.75 (11/30) => 1185\n  CategoricalValue{Float64,UInt32} 3.5 (14/30)  => 731\n  CategoricalValue{Float64,UInt32} 1.25 (5/30)  => 9\n  CategoricalValue{Float64,UInt32} 6.25 (25/30) => 2\n  CategoricalValue{Float64,UInt32} 8.0 (30/30)  => 2\n  CategoricalValue{Float64,UInt32} 6.0 (24/30)  => 6\n  CategoricalValue{Float64,UInt32} 5.25 (21/30) => 13\n  CategoricalValue{Float64,UInt32} 4.0 (16/30)  => 136\n  CategoricalValue{Float64,UInt32} 2.25 (9/30)  => 2047\n  CategoricalValue{Float64,UInt32} 1.75 (7/30)  => 3048\n  CategoricalValue{Float64,UInt32} 0.5 (2/30)   => 4\n  CategoricalValue{Float64,UInt32} 3.0 (12/30)  => 753\n  CategoricalValue{Float64,UInt32} 4.25 (17/30) => 79\n  CategoricalValue{Float64,UInt32} 7.75 (29/30) => 1\n  CategoricalValue{Float64,UInt32} 5.0 (20/30)  => 21\n  CategoricalValue{Float64,UInt32} 3.75 (15/30) => 155\n  CategoricalValue{Float64,UInt32} 5.75 (23/30) => 4\n  CategoricalValue{Float64,UInt32} 7.5 (28/30)  => 1\n  CategoricalValue{Float64,UInt32} 2.5 (10/30)  => 5380\n  CategoricalValue{Float64,UInt32} 0.75 (3/30)  => 72\n  CategoricalValue{Float64,UInt32} 1.0 (4/30)   => 3852"
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "cell_type": "code",
   "source": [
    "import StatsBase.countmap\n",
    "countmap(house.bathrooms)"
   ],
   "metadata": {},
   "execution_count": 113
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ex 4 solution"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "4(a)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are *no* models that apply immediately:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0-element Array{NamedTuple{(:name, :package_name, :is_supervised, :docstring, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :is_pure_julia, :is_wrapper, :load_path, :package_license, :package_url, :package_uuid, :prediction_type, :supports_online, :supports_weights, :input_scitype, :target_scitype, :output_scitype),T} where T<:Tuple,1}"
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "cell_type": "code",
   "source": [
    "models(matching(X4, y4))"
   ],
   "metadata": {},
   "execution_count": 114
  },
  {
   "cell_type": "markdown",
   "source": [
    "4(b)"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4-element Array{NamedTuple{(:name, :package_name, :is_supervised, :docstring, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :is_pure_julia, :is_wrapper, :load_path, :package_license, :package_url, :package_uuid, :prediction_type, :supports_online, :supports_weights, :input_scitype, :target_scitype, :output_scitype),T} where T<:Tuple,1}:\n (name = ConstantRegressor, package_name = MLJModels, ... )\n (name = DecisionTreeRegressor, package_name = DecisionTree, ... )\n (name = DeterministicConstantRegressor, package_name = MLJModels, ... )\n (name = RandomForestRegressor, package_name = DecisionTree, ... )"
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "cell_type": "code",
   "source": [
    "y4 = coerce(y4, Continuous);\n",
    "models(matching(X4, y4))"
   ],
   "metadata": {},
   "execution_count": 115
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ex 6 solution"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "6(a)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "y, X = unpack(horse,\n",
    "              ==(:outcome),\n",
    "              name -> elscitype(Tables.getcolumn(horse, name)) == Continuous);"
   ],
   "metadata": {},
   "execution_count": 116
  },
  {
   "cell_type": "markdown",
   "source": [
    "6(b)(i)"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{LogisticClassifier} @869\u001b[39m.\n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/machines.jl:317\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(classes = CategoricalValue{Int64,UInt32}[1, 2, 3],\n coefs = Pair{Symbol,SubArray{Float64,1,Array{Float64,2},Tuple{Int64,Base.Slice{Base.OneTo{Int64}}},true}}[:rectal_temperature => [0.061700165020208884, -0.06507181615992094, 0.003371651139712025], :pulse => [-0.009584825599058816, 0.004022558646948241, 0.005562266952111324], :respiratory_rate => [-0.009584825599058816, 0.004022558646948241, 0.005562266952111324], :packed_cell_volume => [-0.0430937217634404, 0.020859863954344793, 0.02223385780909599], :total_protein => [0.02750875236570991, -0.06317268044006659, 0.03566392807435661]],\n intercept = [0.0008917387282688827, -0.0008917385123632456, -4.972412452088422],)"
     },
     "metadata": {},
     "execution_count": 117
    }
   ],
   "cell_type": "code",
   "source": [
    "model = @load LogisticClassifier pkg=MLJLinearModels;\n",
    "model.lambda = 100\n",
    "mach = machine(model, X, y)\n",
    "fit!(mach, rows=train)\n",
    "fitted_params(mach)"
   ],
   "metadata": {},
   "execution_count": 117
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7187276476280999"
     },
     "metadata": {},
     "execution_count": 118
    }
   ],
   "cell_type": "code",
   "source": [
    "coefs_given_feature = Dict(fitted_params(mach).coefs)\n",
    "coefs_given_feature[:pulse]\n",
    "\n",
    "#6(b)(ii)\n",
    "\n",
    "yhat = predict(mach, rows=test); # or predict(mach, X[test,:])\n",
    "err = cross_entropy(yhat, y[test]) |> mean"
   ],
   "metadata": {},
   "execution_count": 118
  },
  {
   "cell_type": "markdown",
   "source": [
    "6(b)(iii)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The predicted probabilities of the actual observations in the test\n",
    "are given by"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "p = broadcast(pdf, yhat, y[test]);"
   ],
   "metadata": {},
   "execution_count": 119
  },
  {
   "cell_type": "markdown",
   "source": [
    "The number of times this probability exceeds 50% is:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "30"
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "cell_type": "code",
   "source": [
    "n50 = filter(x -> x > 0.5, p) |> length"
   ],
   "metadata": {},
   "execution_count": 120
  },
  {
   "cell_type": "markdown",
   "source": [
    "Or, as a proportion:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.6666666666666666"
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "cell_type": "code",
   "source": [
    "n50/length(test)"
   ],
   "metadata": {},
   "execution_count": 121
  },
  {
   "cell_type": "markdown",
   "source": [
    "6(b)(iv)"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.28888888888888886"
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "cell_type": "code",
   "source": [
    "misclassification_rate(mode.(yhat), y[test])"
   ],
   "metadata": {},
   "execution_count": 122
  },
  {
   "cell_type": "markdown",
   "source": [
    "6(c)(i)"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\rEvaluating over 6 folds:  17%[====>                    ]  ETA: 0:00:00\u001b[K\rEvaluating over 6 folds:  33%[========>                ]  ETA: 0:00:00\u001b[K\rEvaluating over 6 folds:  50%[============>            ]  ETA: 0:00:00\u001b[K\rEvaluating over 6 folds:  67%[================>        ]  ETA: 0:00:00\u001b[K\rEvaluating over 6 folds:  83%[====================>    ]  ETA: 0:00:00\u001b[K\rEvaluating over 6 folds: 100%[=========================] Time: 0:00:00\u001b[K\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "MLJBase.NumericRange(Int64, :n_trees, ... )"
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "cell_type": "code",
   "source": [
    "model = @load RandomForestClassifier pkg=DecisionTree\n",
    "mach = machine(model, X, y)\n",
    "evaluate!(mach, resampling=CV(nfolds=6), measure=cross_entropy)\n",
    "\n",
    "r = range(model, :n_trees, lower=10, upper=70, scale=:log)"
   ],
   "metadata": {},
   "execution_count": 123
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since random forests are inherently randomized, we generate multiple\n",
    "curves:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "plt = plot()\n",
    "for i in 1:4\n",
    "    curve = learning_curve(mach,\n",
    "                           range=r,\n",
    "                           resampling=Holdout(),\n",
    "                           measure=cross_entropy)\n",
    "    plt=plot!(curve.parameter_values, curve.measurements)\n",
    "end\n",
    "xlabel!(plt, \"n_trees\")\n",
    "ylabel!(plt, \"cross entropy\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "6(c)(ii)"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Info: Creating subsamples from a subset of all rows. \n",
      "└ @ MLJBase /Users/anthony/.julia/packages/MLJBase/r3heT/src/resampling.jl:336\n",
      "\rEvaluating over 9 folds:  11%[==>                      ]  ETA: 0:00:00\u001b[K\rEvaluating over 9 folds:  22%[=====>                   ]  ETA: 0:00:00\u001b[K\rEvaluating over 9 folds:  33%[========>                ]  ETA: 0:00:00\u001b[K\rEvaluating over 9 folds:  44%[===========>             ]  ETA: 0:00:00\u001b[K\rEvaluating over 9 folds:  56%[=============>           ]  ETA: 0:00:00\u001b[K\rEvaluating over 9 folds:  67%[================>        ]  ETA: 0:00:00\u001b[K\rEvaluating over 9 folds:  78%[===================>     ]  ETA: 0:00:00\u001b[K\rEvaluating over 9 folds:  89%[======================>  ]  ETA: 0:00:00\u001b[K\rEvaluating over 9 folds: 100%[=========================] Time: 0:00:00\u001b[K\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "90"
     },
     "metadata": {},
     "execution_count": 124
    }
   ],
   "cell_type": "code",
   "source": [
    "evaluate!(mach, resampling=CV(nfolds=9),\n",
    "                measure=cross_entropy,\n",
    "                rows=train).measurement[1]\n",
    "\n",
    "model.n_trees = 90"
   ],
   "metadata": {},
   "execution_count": 124
  },
  {
   "cell_type": "markdown",
   "source": [
    "6(c)(iii)"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1.2903445418223982"
     },
     "metadata": {},
     "execution_count": 125
    }
   ],
   "cell_type": "code",
   "source": [
    "err_forest = evaluate!(mach, resampling=Holdout(),\n",
    "                       measure=cross_entropy).measurement[1]"
   ],
   "metadata": {},
   "execution_count": 125
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  },
  "kernelspec": {
   "name": "julia-1.4",
   "display_name": "Julia 1.4.2",
   "language": "julia"
  }
 },
 "nbformat": 4
}
